{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35867555",
   "metadata": {},
   "source": [
    "# MSTA 6102 — CAT (Stats)\n",
    "\n",
    "\n",
    "*Complete annotated solution — manual math + code + reproducible outputs*\n",
    "\n",
    "\n",
    "**Author:** Daniel Wanjala  \n",
    "**Date:** 2025-10-06 (auto-generated when the setup cell runs)  \n",
    "**Kernel:** Python 3\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### What you will find inside\n",
    "\n",
    "\n",
    "- Exhaustive manual derivations in LaTeX for all three CAT questions, followed by mirrored Python code.\n",
    "- Reproducible analysis pipeline with deterministic random seed, dependency checks, and saved artifacts.\n",
    "- Visual diagnostics (forest plots, ROC, calibration, residual heatmaps) and effect-size tables.\n",
    "- Automated saving of tables/figures, a one-page report, and an HTML slide deck under `outputs/`.\n",
    "- Optional extras: bootstrap/interactive widgets, sensitivity simulations, and a cleanup helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e09312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ The following packages are missing and might be needed for optional steps:\n",
      "    fpdf, weasyprint\n",
      "   Run this command if you have write access:\n",
      "   pip install fpdf weasyprint\n",
      "Python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n",
      "Run datetime (UTC): 2025-10-05 22:51 UTC\n",
      "Random seed set to: 42\n",
      "Outputs directory: C:\\Users\\MadScie254\\Documents\\GitHub\\Stats_CAT_2.1\\outputs\n",
      "Core package versions:\n",
      "  numpy        2.1.3\n",
      "  pandas       2.3.2\n",
      "  matplotlib   3.10.6\n",
      "  seaborn      0.13.2\n",
      "  scipy        1.16.2\n",
      "  statsmodels  0.14.5\n",
      "  sklearn      not-installed\n",
      "Core package versions:\n",
      "  numpy        2.1.3\n",
      "  pandas       2.3.2\n",
      "  matplotlib   3.10.6\n",
      "  seaborn      0.13.2\n",
      "  scipy        1.16.2\n",
      "  statsmodels  0.14.5\n",
      "  sklearn      not-installed\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Notebook run date:** 2025-10-05 22:51 UTC &nbsp;&nbsp; | &nbsp;&nbsp; **Random seed:** 42"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup & imports\n",
    "# This cell verifies key dependencies, sets deterministic seeds, and prepares a workspace for outputs.\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "RUN_DATETIME = datetime.datetime.now(datetime.timezone.utc)\n",
    "RUN_DATE_STR = RUN_DATETIME.strftime(\"%Y-%m-%d %H:%M %Z\") or RUN_DATETIME.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Packages required throughout the notebook\n",
    "REQUIRED_PACKAGES = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scipy\",\n",
    "    \"statsmodels\",\n",
    "    \"sklearn\",\n",
    "    \"ipywidgets\",\n",
    "    \"nbconvert\",\n",
    "    \"weasyprint\",\n",
    "    \"fpdf\",\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for pkg in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        missing.append(pkg)\n",
    "\n",
    "if missing:\n",
    "    pip_cmd = \"pip install \" + \" \".join(sorted(missing))\n",
    "    print(\"⚠️ The following packages are missing and might be needed for optional steps:\")\n",
    "    print(\"   \", \", \".join(sorted(missing)))\n",
    "    print(\"   Run this command if you have write access:\")\n",
    "    print(f\"   {pip_cmd}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.contingency_tables import Table2x2\n",
    "from statsmodels.stats import outliers_influence as sm_outliers_influence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Ensure `sm.stats.outliers_influence` exposes variance_inflation_factor even when the\n",
    "# statsmodels API layout changes between versions.\n",
    "setattr(sm.stats, \"outliers_influence\", sm_outliers_influence)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"deep\")\n",
    "plt.rcParams.update({\"figure.figsize\": (8, 5), \"axes.titleweight\": \"bold\"})\n",
    "\n",
    "OUTDIR = Path(\"outputs\")\n",
    "OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_NAME = \"MSTA_6102_CAT_Stats.ipynb\"\n",
    "EXPORT_SLIDES = True\n",
    "DO_BOOTSTRAP = True\n",
    "BOOTSTRAP_REPS = 10_000\n",
    "\n",
    "try:\n",
    "    from IPython.display import Markdown, display\n",
    "except ImportError:  # pragma: no cover\n",
    "    Markdown = None\n",
    "    display = None\n",
    "\n",
    "ENV_SUMMARY = {\n",
    "    \"python_version\": sys.version.splitlines()[0],\n",
    "    \"run_datetime_utc\": RUN_DATE_STR,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "print(\"Python:\", ENV_SUMMARY[\"python_version\"])\n",
    "print(\"Run datetime (UTC):\", ENV_SUMMARY[\"run_datetime_utc\"])\n",
    "print(\"Random seed set to:\", RANDOM_SEED)\n",
    "print(\"Outputs directory:\", OUTDIR.resolve())\n",
    "\n",
    "try:\n",
    "    import pkg_resources\n",
    "    core_versions = {}\n",
    "    for name in [\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scipy\", \"statsmodels\", \"sklearn\"]:\n",
    "        try:\n",
    "            version = pkg_resources.get_distribution(name).version\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            version = \"not-installed\"\n",
    "        core_versions[name] = version\n",
    "    print(\"Core package versions:\")\n",
    "    for k, v in core_versions.items():\n",
    "        print(f\"  {k:<12} {v}\")\n",
    "except Exception as exc:  # pragma: no cover\n",
    "    print(\"Could not summarise package versions:\", exc)\n",
    "\n",
    "if display and Markdown:\n",
    "    display(Markdown(f\"**Notebook run date:** {RUN_DATE_STR} &nbsp;&nbsp; | &nbsp;&nbsp; **Random seed:** {RANDOM_SEED}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2b9aa",
   "metadata": {},
   "source": [
    "## How to run this notebook\n",
    "\n",
    "\n",
    "1. **Kernel**: Python 3. Run this notebook from a virtual environment with write access to the repo so outputs can be saved under `outputs/`.\n",
    "\n",
    "\n",
    "2. **Install dependencies (if prompted)**: the setup cell checks for `numpy`, `pandas`, `matplotlib`, `seaborn`, `scipy`, `statsmodels`, `sklearn`, `ipywidgets`, `nbconvert`, `weasyprint`, and `fpdf`. If any are missing, copy the printed `pip install ...` command into a terminal.\n",
    "\n",
    "\n",
    "3. **Execution order**: Restart the kernel, run all cells from top to bottom. The random seed is fixed (`42`) for reproducibility, and bootstrap results will match the manual derivations within rounding error.\n",
    "\n",
    "\n",
    "4. **Expected runtime**: ~2–4 minutes on a modern laptop (bootstrap + slide export dominate). Set `DO_BOOTSTRAP = False` or `EXPORT_SLIDES = False` near the top if you need a faster run.\n",
    "\n",
    "\n",
    "5. **Outputs**: Figures, tables, markdown/PDF reports, and slides are written into `outputs/`. A final log cell lists every generated artifact.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "1. [Question 1 — Seat-belt use and fatal road injuries](#q1)\n",
    "2. [Question 2 — Endometrial cancer and oral contraceptive (Oracon) use](#q2)\n",
    "3. [Question 3 — Logistic/Poisson regression mini-project](#q3)\n",
    "4. [Consolidated results, slides, and clean-up utilities](#results)\n",
    "5. [Conclusions & Limitations](#conclusions)\n",
    "6. [References](#references)\n",
    "7. [Output log](#outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e60da9",
   "metadata": {},
   "source": [
    "<a id=\"q1\"></a>\n",
    "# Question 1 — Seat-belt use and fatal road injuries\n",
    "\n",
    "\n",
    "We revisit a cross-sectional dataset where crash victims are classified by **safety equipment** (seat belt vs none) and **injury outcome** (fatal vs non-fatal). The aim is to compute absolute and relative measures of association, quantify uncertainty, and interpret the findings for public-safety policy.\n",
    "\n",
    "\n",
    "\n",
    "The observed 2×2 contingency table is reproduced below:\n",
    "\n",
    "\n",
    "\n",
    "| Safety equipment | Fatal (count) | Non-fatal (count) | Row total |\n",
    "| ---------------- | ------------: | ----------------: | --------: |\n",
    "| None             | 189           | 10,843            | 11,032    |\n",
    "| Seat belt        | 104           | 10,933            | 11,037    |\n",
    "| **Column totals** | **293**       | **21,776**        | **22,069** |\n",
    "\n",
    "\n",
    "\n",
    "- Event of interest: fatal crash outcome.\n",
    "- Exposure: not wearing a seat belt (`None`).\n",
    "- All downstream manual calculations and Python code will use the counts `(a, b, c, d) = (189, 10,843, 104, 10,933)`.\n",
    "\n",
    "\n",
    "\n",
    "We proceed with meticulous manual derivations followed by mirroring Python code, then extend the analysis with alternative confidence intervals, hypothesis tests, and visual diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb126736",
   "metadata": {},
   "source": [
    "## Q1.1 Manual derivations (LaTeX + digit-by-digit arithmetic)\n",
    "\n",
    "\n",
    "We label the cells of the 2×2 table as:\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{array}{c|cc|c}\n",
    "\\text{Safety equipment} & \\text{Fatal} & \\text{Non-fatal} & \\text{Row total}\\\\ \\hline\n",
    "\\text{None} & a = 189 & b = 10{,}843 & n_1 = a + b = 189 + 10{,}843 = 11{,}032 \\\\\n",
    "\\text{Seat belt} & c = 104 & d = 10{,}933 & n_2 = c + d = 104 + 10{,}933 = 11{,}037 \\\\\n",
    "\\hline\n",
    "\\text{Column totals} & a + c = 293 & b + d = 21{,}776 & N = n_1 + n_2 = 22{,}069\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "### Risks (prevalences)\n",
    "\n",
    "\n",
    "\n",
    "For the exposed group (no seat belt):\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "p_1 &= \\frac{a}{n_1} = \\frac{189}{11{,}032} \\\\\n",
    "&= \\frac{189}{11{,}032} = \\frac{189.000000}{11{,}032.000000} \\\\\n",
    "&= 0.01713197969543147 \\text{ (computed as long division)} \\\\\n",
    "&= 1.713197969543147\\% \\; (= 17.13197969543147 \\text{ per 1,000}).\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "For the comparison group (seat belt):\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "p_2 &= \\frac{c}{n_2} = \\frac{104}{11{,}037} \\\\\n",
    "&= \\frac{104}{11{,}037} = \\frac{104.000000}{11{,}037.000000} \\\\\n",
    "&= 0.009422850412249705 \\\\\n",
    "&= 0.9422850412249705\\% \\; (= 9.422850412249705 \\text{ per 1,000}).\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "### Risk difference (absolute effect)\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "RD &= p_1 - p_2 \\\\\n",
    "&= 0.01713197969543147 - 0.009422850412249705 \\\\\n",
    "&= 0.007709129283181765 \\\\\n",
    "&= 0.7709129283181765\\% \\; (\\text{≈ } 7.709 fatal injuries per 1,000 additional when the seat belt is not used}).\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "### Relative risk (risk ratio)\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "RR &= \\frac{p_1}{p_2} \\\\\n",
    "&= \\frac{0.01713197969543147}{0.009422850412249705} \\\\\n",
    "&= 1.818131345177665.\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Interpretation: individuals without seat belts experience **1.818×** the risk of a fatal outcome relative to people wearing seat belts.\n",
    "\n",
    "\n",
    "\n",
    "### Odds ratio\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\text{Odds}_{\\text{none}} &= \\frac{a}{b} = \\frac{189}{10{,}843} = 0.01743351082823446, \\\\\n",
    "\\text{Odds}_{\\text{belt}} &= \\frac{c}{d} = \\frac{104}{10{,}933} = 0.009510412553305354.\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "OR &= \\frac{\\text{Odds}_{\\text{none}}}{\\text{Odds}_{\\text{belt}}} = \\frac{a d}{b c} \\\\\n",
    "&= \\frac{189 \\times 10{,}933}{10{,}843 \\times 104} \\\\\n",
    "&= \\frac{189 \\times 10{,}933 = 2{,}066{,}337}{10{,}843 \\times 104 = 1{,}127{,}672} \\\\\n",
    "&= \\frac{2{,}066{,}337}{1{,}127{,}672} = 1.8323918657198193.\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Interpretation: the odds of a fatal outcome are **1.832×** higher without a seat belt.\n",
    "\n",
    "\n",
    "\n",
    "### Why OR ≈ RR under the rare-disease assumption\n",
    "\n",
    "\n",
    "\n",
    "Because both risks are small (1.71% vs 0.94%), the odds and probability are nearly identical: e.g., for the exposed group\n",
    "\\[\n",
    "\\text{Odds}_{\\text{none}} = \\frac{0.0171319797}{1 - 0.0171319797} = 0.0174335108,\n",
    "\\]\n",
    "which differs from the risk by only 0.0003015311. Consequently, **OR = 1.832** and **RR = 1.818** differ by only 0.014 – a negligible amount compared with their magnitudes.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Standard errors and confidence intervals (Wald/log method)\n",
    "\n",
    "\n",
    "\n",
    "All confidence intervals below are two-sided 95% intervals with critical value $z_{0.975} = 1.96$.\n",
    "\n",
    "\n",
    "\n",
    "#### Risk difference\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(RD) = \\sqrt{\\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Plugging in the values step-by-step:\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\frac{p_1 (1 - p_1)}{n_1} = \\frac{0.0171319797 \\times (1 - 0.0171319797)}{11{,}032} = \\frac{0.0171319797 \\times 0.9828680203}{11{,}032} = \\frac{0.0168373370}{11{,}032} = 1.5257214 \\times 10^{-6}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\frac{p_2 (1 - p_2)}{n_2} = \\frac{0.0094228504 \\times (1 - 0.0094228504)}{11{,}037} = \\frac{0.0094228504 \\times 0.9905771496}{11{,}037} = \\frac{0.0093350410}{11{,}037} = 8.4606620 \\times 10^{-7}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(RD) = \\sqrt{1.5257214 \\times 10^{-6} + 8.4606620 \\times 10^{-7}} = \\sqrt{2.3717876 \\times 10^{-6}} = 0.0015399126.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "CI_{95\\%}(RD) = RD \\pm 1.96 \\times SE(RD) = 0.0077091293 \\pm 1.96 \\times 0.0015399126 = 0.0077091293 \\pm 0.0030222157.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Therefore\n",
    "\\[\n",
    "CI_{95\\%}(RD) = (0.0046869136,\\; 0.0107313450),\n",
    "\\]\n",
    "which corresponds to **(4.687, 10.731) additional fatalities per 1,000**.\n",
    "\n",
    "\n",
    "\n",
    "#### Relative risk (log method)\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(\\log RR) = \\sqrt{\\frac{1 - p_1}{a} + \\frac{1 - p_2}{c} - \\frac{1}{n_1} - \\frac{1}{n_2}} = \\sqrt{\\frac{1}{a} - \\frac{1}{n_1} + \\frac{1}{c} - \\frac{1}{n_2}}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "We compute term-by-term:\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\frac{1}{a} - \\frac{1}{n_1} = \\frac{1}{189} - \\frac{1}{11{,}032} = 0.0052910053 - 0.0000906286 = 0.0052003767.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\frac{1}{c} - \\frac{1}{n_2} = \\frac{1}{104} - \\frac{1}{11{,}037} = 0.0096153846 - 0.0000905974 = 0.0095247872.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(\\log RR) = \\sqrt{0.0052003767 + 0.0095247872} = \\sqrt{0.0147251639} = 0.1213318006.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\log RR = \\log(1.8181313452) = 0.5977470198.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "CI_{95\\%}(\\log RR) = 0.5977470198 \\pm 1.96 \\times 0.1213318006 = 0.5977470198 \\pm 0.2378113292.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Exponentiating the bounds gives\n",
    "\\[\n",
    "CI_{95\\%}(RR) = (e^{0.3599356906},\\; e^{0.8355583490}) = (1.4333114589,\\; 2.3063355892).\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "#### Odds ratio (log method)\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(\\log OR) = \\sqrt{\\frac{1}{a} + \\frac{1}{b} + \\frac{1}{c} + \\frac{1}{d}}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\frac{1}{a} = 0.0052910053,\\; \\frac{1}{b} = 0.0000922160,\\; \\frac{1}{c} = 0.0096153846,\\; \\frac{1}{d} = 0.0000914825.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(\\log OR) = \\sqrt{0.0052910053 + 0.0000922160 + 0.0096153846 + 0.0000914825} = \\sqrt{0.015089,} = 0.1228769847.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\log OR = \\log(1.8323918657) = 0.6067856974.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "CI_{95\\%}(\\log OR) = 0.6067856974 \\pm 1.96 \\times 0.1228769847 = 0.6067856974 \\pm 0.2408359010.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "CI_{95\\%}(OR) = (e^{0.3659497964},\\; e^{0.8476215984}) = (1.4413554590,\\; 2.3333436857).\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "These intervals exclude the null values (0 for RD, 1 for RR/OR), confirming statistically significant evidence that not wearing a seat belt increases the chance of a fatal injury."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66691077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 point estimates (mirroring manual derivations):\n",
      "           Measure  Point estimate                        95% CI  Per 1,000  \\\n",
      "0  Risk difference        0.007709  (0.0046905070, 0.0107277516)      7.709   \n",
      "1    Relative risk        1.818131          (1.433291, 2.306302)        NaN   \n",
      "2       Odds ratio        1.832392          (1.440308, 2.331210)        NaN   \n",
      "\n",
      "                                      Interpretation  \n",
      "0  Additional fatalities per 1,000 when no seat b...  \n",
      "1  Multiplicative change in risk for no seat belt...  \n",
      "2  Multiplicative change in odds (case-control an...  \n",
      "Saved table → outputs\\q1_summary_measures.csv\n"
     ]
    }
   ],
   "source": [
    "# Q1.2 Mirroring the manual derivations in Python\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "Q1_COUNTS = {\"a\": 189, \"b\": 10_843, \"c\": 104, \"d\": 10_933}\n",
    "\n",
    "\n",
    "def compute_2x2_measures(a: int, b: int, c: int, d: int, alpha: float = 0.05, digits: int = 10) -> Dict[str, float]:\n",
    "    \"\"\"Return a dictionary of risk-based measures, their SEs, and Wald/log CIs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b, c, d : int\n",
    "        Cell counts where rows correspond to exposure (row 1 = exposed) and columns to outcome (col 1 = event).\n",
    "    alpha : float\n",
    "        Significance level for confidence intervals (default 0.05 for 95% CI).\n",
    "    digits : int\n",
    "        Rounding digits when storing values (presentation handled downstream).\n",
    "    \"\"\"\n",
    "    n1 = a + b\n",
    "    n2 = c + d\n",
    "    N = n1 + n2\n",
    "\n",
    "    p1 = a / n1\n",
    "    p2 = c / n2\n",
    "\n",
    "    rd = p1 - p2\n",
    "    rr = p1 / p2\n",
    "    oratio = (a * d) / (b * c)\n",
    "\n",
    "    # Standard errors\n",
    "    se_rd = math.sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)\n",
    "    se_log_rr = math.sqrt((1 / a) - (1 / n1) + (1 / c) - (1 / n2))\n",
    "    se_log_or = math.sqrt((1 / a) + (1 / b) + (1 / c) + (1 / d))\n",
    "\n",
    "    z = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    rd_ci = (rd - z * se_rd, rd + z * se_rd)\n",
    "    log_rr = math.log(rr)\n",
    "    rr_ci = (math.exp(log_rr - z * se_log_rr), math.exp(log_rr + z * se_log_rr))\n",
    "    log_or = math.log(oratio)\n",
    "    or_ci = (math.exp(log_or - z * se_log_or), math.exp(log_or + z * se_log_or))\n",
    "\n",
    "    return {\n",
    "        \"n1\": n1,\n",
    "        \"n2\": n2,\n",
    "        \"N\": N,\n",
    "        \"p1\": p1,\n",
    "        \"p2\": p2,\n",
    "        \"rd\": rd,\n",
    "        \"rr\": rr,\n",
    "        \"or\": oratio,\n",
    "        \"se_rd\": se_rd,\n",
    "        \"se_log_rr\": se_log_rr,\n",
    "        \"se_log_or\": se_log_or,\n",
    "        \"rd_ci_low\": rd_ci[0],\n",
    "        \"rd_ci_high\": rd_ci[1],\n",
    "        \"rr_ci_low\": rr_ci[0],\n",
    "        \"rr_ci_high\": rr_ci[1],\n",
    "        \"or_ci_low\": or_ci[0],\n",
    "        \"or_ci_high\": or_ci[1],\n",
    "    }\n",
    "\n",
    "\n",
    "def per_1000(value: float) -> float:\n",
    "    \"\"\"Convert a proportion to a per-1,000 rate.\"\"\"\n",
    "    return value * 1000\n",
    "\n",
    "\n",
    "def format_interval(lo: float, hi: float, decimals: int = 6) -> str:\n",
    "    return f\"({lo:.{decimals}f}, {hi:.{decimals}f})\"\n",
    "\n",
    "\n",
    "def savefig(filename: str, *, dpi: int = 300, bbox_inches: str = \"tight\", pad_inches: float = 0.05,\n",
    "            tight_layout: bool = True) -> Path:\n",
    "    \"\"\"Save the current matplotlib figure to `outputs/filename` and return the path.\"\"\"\n",
    "    if tight_layout:\n",
    "        try:\n",
    "            plt.tight_layout()\n",
    "        except Exception:\n",
    "            pass\n",
    "    path = OUTDIR / filename\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=bbox_inches, pad_inches=pad_inches)\n",
    "    print(f\"Saved figure → {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "results_q1 = compute_2x2_measures(**Q1_COUNTS)\n",
    "\n",
    "manual_reference = {\n",
    "    \"rd\": 0.007709129283181765,\n",
    "    \"rr\": 1.818131345177665,\n",
    "    \"or\": 1.8323918657198193,\n",
    "}\n",
    "\n",
    "for key, target in manual_reference.items():\n",
    "    assert np.isclose(results_q1[key], target, rtol=0, atol=1e-12), f\"Mismatch for {key}\"  # tight tolerance\n",
    "\n",
    "summary_rows = [\n",
    "    {\n",
    "        \"Measure\": \"Risk difference\",\n",
    "        \"Point estimate\": results_q1[\"rd\"],\n",
    "        \"95% CI\": format_interval(results_q1[\"rd_ci_low\"], results_q1[\"rd_ci_high\"], decimals=10),\n",
    "        \"Per 1,000\": per_1000(results_q1[\"rd\"]),\n",
    "        \"Interpretation\": \"Additional fatalities per 1,000 when no seat belt is used\",\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Relative risk\",\n",
    "        \"Point estimate\": results_q1[\"rr\"],\n",
    "        \"95% CI\": format_interval(results_q1[\"rr_ci_low\"], results_q1[\"rr_ci_high\"]),\n",
    "        \"Per 1,000\": np.nan,\n",
    "        \"Interpretation\": \"Multiplicative change in risk for no seat belt vs seat belt\",\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Odds ratio\",\n",
    "        \"Point estimate\": results_q1[\"or\"],\n",
    "        \"95% CI\": format_interval(results_q1[\"or_ci_low\"], results_q1[\"or_ci_high\"]),\n",
    "        \"Per 1,000\": np.nan,\n",
    "        \"Interpretation\": \"Multiplicative change in odds (case-control analogue)\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_path = OUTDIR / \"q1_summary_measures.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"Q1 point estimates (mirroring manual derivations):\")\n",
    "print(summary_df.assign(**{\"Point estimate\": summary_df[\"Point estimate\"].round(10), \"Per 1,000\": summary_df[\"Per 1,000\"].round(3)}))\n",
    "print(f\"Saved table → {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ceda87",
   "metadata": {},
   "source": [
    "### Q1.3 Alternative confidence intervals and resampling\n",
    "\n",
    "\n",
    "To complement the Wald/log intervals, we compute:\n",
    "\n",
    "\n",
    "\n",
    "1. **Exact/score-based intervals** from `statsmodels`' `Table2x2`, which implements score methods for risk and odds ratios.\n",
    "2. **Bootstrap intervals** for the risk difference and relative risk using 10,000 resamples of the individual-level data reconstructed from the 2×2 table.\n",
    "\n",
    "\n",
    "\n",
    "The bootstrap includes a toggle `DO_BOOTSTRAP` so the notebook can be sped up when needed. Each result is compared with the earlier manual computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ea0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score-based intervals (statsmodels):\n",
      "  RR score CI  : (1.433291, 2.306302)\n",
      "  OR score CI  : (1.440308, 2.331210)\n",
      "Bootstrap CI (RD, 10,000 reps): (0.004705127507227079, 0.010768251574704806)\n",
      "Bootstrap CI (RR, 10,000 reps): (1.4410559302429347, 2.32849875018109)\n",
      "Saved CI comparison table → outputs\\q1_ci_comparison.csv\n",
      "Bootstrap CI (RD, 10,000 reps): (0.004705127507227079, 0.010768251574704806)\n",
      "Bootstrap CI (RR, 10,000 reps): (1.4410559302429347, 2.32849875018109)\n",
      "Saved CI comparison table → outputs\\q1_ci_comparison.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Measure",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lower",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Upper",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "fa887d99-617b-48b7-95de-22dc1607f7af",
       "rows": [
        [
         "0",
         "Risk difference",
         "Wald",
         "0.004690506988105671",
         "0.010727751578257862"
        ],
        [
         "1",
         "Risk difference",
         "Bootstrap",
         "0.004705127507227079",
         "0.010768251574704806"
        ],
        [
         "2",
         "Relative risk",
         "Log-Wald",
         "1.4332908885358975",
         "2.3063019619794054"
        ],
        [
         "3",
         "Relative risk",
         "Bootstrap",
         "1.4410559302429347",
         "2.32849875018109"
        ],
        [
         "4",
         "Relative risk",
         "Score (Table2x2)",
         "1.4332908885358973",
         "2.306301961979406"
        ],
        [
         "5",
         "Odds ratio",
         "Log-Wald",
         "1.440307813392208",
         "2.33120998048897"
        ],
        [
         "6",
         "Odds ratio",
         "Score (Table2x2)",
         "1.4403078133922094",
         "2.3312099804889725"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Method</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risk difference</td>\n",
       "      <td>Wald</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.010728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Risk difference</td>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relative risk</td>\n",
       "      <td>Log-Wald</td>\n",
       "      <td>1.433291</td>\n",
       "      <td>2.306302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relative risk</td>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>1.441056</td>\n",
       "      <td>2.328499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relative risk</td>\n",
       "      <td>Score (Table2x2)</td>\n",
       "      <td>1.433291</td>\n",
       "      <td>2.306302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Odds ratio</td>\n",
       "      <td>Log-Wald</td>\n",
       "      <td>1.440308</td>\n",
       "      <td>2.331210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Odds ratio</td>\n",
       "      <td>Score (Table2x2)</td>\n",
       "      <td>1.440308</td>\n",
       "      <td>2.331210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Measure            Method     Lower     Upper\n",
       "0  Risk difference              Wald  0.004691  0.010728\n",
       "1  Risk difference         Bootstrap  0.004705  0.010768\n",
       "2    Relative risk          Log-Wald  1.433291  2.306302\n",
       "3    Relative risk         Bootstrap  1.441056  2.328499\n",
       "4    Relative risk  Score (Table2x2)  1.433291  2.306302\n",
       "5       Odds ratio          Log-Wald  1.440308  2.331210\n",
       "6       Odds ratio  Score (Table2x2)  1.440308  2.331210"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.3 Implementation: score-based intervals and bootstrap\n",
    "contingency_q1 = np.array([[Q1_COUNTS[\"a\"], Q1_COUNTS[\"b\"]],\n",
    "                           [Q1_COUNTS[\"c\"], Q1_COUNTS[\"d\"]]])\n",
    "\n",
    "sc_table = Table2x2(contingency_q1)\n",
    "score_rr_low, score_rr_high = sc_table.riskratio_confint()\n",
    "score_or_low, score_or_high = sc_table.oddsratio_confint()\n",
    "print(\"Score-based intervals (statsmodels):\")\n",
    "print(f\"  RR score CI  : ({score_rr_low:.6f}, {score_rr_high:.6f})\")\n",
    "print(f\"  OR score CI  : ({score_or_low:.6f}, {score_or_high:.6f})\")\n",
    "\n",
    "\n",
    "def expand_2x2_to_records(a: int, b: int, c: int, d: int) -> pd.DataFrame:\n",
    "    \"\"\"Return an individual-level DataFrame from 2x2 counts.\"\"\"\n",
    "    exposure = np.concatenate([\n",
    "        np.repeat(\"None\", a + b),\n",
    "        np.repeat(\"Seat belt\", c + d),\n",
    "    ])\n",
    "    outcome = np.concatenate([\n",
    "        np.concatenate([np.ones(a, dtype=int), np.zeros(b, dtype=int)]),\n",
    "        np.concatenate([np.ones(c, dtype=int), np.zeros(d, dtype=int)]),\n",
    "    ])\n",
    "    return pd.DataFrame({\"exposure\": exposure, \"fatal\": outcome})\n",
    "\n",
    "\n",
    "def bootstrap_ci(data: pd.DataFrame,\n",
    "                 stat_fn,\n",
    "                 reps: int = BOOTSTRAP_REPS,\n",
    "                 alpha: float = 0.05,\n",
    "                 random_state: int = RANDOM_SEED) -> Tuple[float, float]:\n",
    "    \"\"\"Generic percentile bootstrap CI.\"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(data)\n",
    "    estimates = np.empty(reps)\n",
    "    for i in range(reps):\n",
    "        sample_idx = rng.integers(0, n, n)\n",
    "        sample = data.iloc[sample_idx]\n",
    "        estimates[i] = stat_fn(sample)\n",
    "    lower = np.quantile(estimates, alpha / 2)\n",
    "    upper = np.quantile(estimates, 1 - alpha / 2)\n",
    "    return float(lower), float(upper)\n",
    "\n",
    "\n",
    "records_q1 = expand_2x2_to_records(**Q1_COUNTS)\n",
    "\n",
    "if DO_BOOTSTRAP:\n",
    "    def rd_stat(df: pd.DataFrame) -> float:\n",
    "        p1 = df.loc[df[\"exposure\"] == \"None\", \"fatal\"].mean()\n",
    "        p2 = df.loc[df[\"exposure\"] == \"Seat belt\", \"fatal\"].mean()\n",
    "        return p1 - p2\n",
    "\n",
    "    def rr_stat(df: pd.DataFrame) -> float:\n",
    "        p1 = df.loc[df[\"exposure\"] == \"None\", \"fatal\"].mean()\n",
    "        p2 = df.loc[df[\"exposure\"] == \"Seat belt\", \"fatal\"].mean()\n",
    "        return p1 / p2\n",
    "\n",
    "    rd_boot = bootstrap_ci(records_q1, rd_stat)\n",
    "    rr_boot = bootstrap_ci(records_q1, rr_stat)\n",
    "    print(f\"Bootstrap CI (RD, {BOOTSTRAP_REPS:,} reps): {rd_boot}\")\n",
    "    print(f\"Bootstrap CI (RR, {BOOTSTRAP_REPS:,} reps): {rr_boot}\")\n",
    "else:\n",
    "    print(\"Bootstrap skipped (set DO_BOOTSTRAP = True to enable).\")\n",
    "\n",
    "ci_compare = pd.DataFrame([\n",
    "    {\n",
    "        \"Measure\": \"Risk difference\",\n",
    "        \"Method\": \"Wald\",\n",
    "        \"Lower\": results_q1[\"rd_ci_low\"],\n",
    "        \"Upper\": results_q1[\"rd_ci_high\"],\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Risk difference\",\n",
    "        \"Method\": \"Bootstrap\",\n",
    "        \"Lower\": rd_boot[0] if DO_BOOTSTRAP else np.nan,\n",
    "        \"Upper\": rd_boot[1] if DO_BOOTSTRAP else np.nan,\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Relative risk\",\n",
    "        \"Method\": \"Log-Wald\",\n",
    "        \"Lower\": results_q1[\"rr_ci_low\"],\n",
    "        \"Upper\": results_q1[\"rr_ci_high\"],\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Relative risk\",\n",
    "        \"Method\": \"Bootstrap\",\n",
    "        \"Lower\": rr_boot[0] if DO_BOOTSTRAP else np.nan,\n",
    "        \"Upper\": rr_boot[1] if DO_BOOTSTRAP else np.nan,\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Relative risk\",\n",
    "        \"Method\": \"Score (Table2x2)\",\n",
    "        \"Lower\": score_rr_low,\n",
    "        \"Upper\": score_rr_high,\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Odds ratio\",\n",
    "        \"Method\": \"Log-Wald\",\n",
    "        \"Lower\": results_q1[\"or_ci_low\"],\n",
    "        \"Upper\": results_q1[\"or_ci_high\"],\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Odds ratio\",\n",
    "        \"Method\": \"Score (Table2x2)\",\n",
    "        \"Lower\": score_or_low,\n",
    "        \"Upper\": score_or_high,\n",
    "    },\n",
    "])\n",
    "ci_compare_path = OUTDIR / \"q1_ci_comparison.csv\"\n",
    "ci_compare.to_csv(ci_compare_path, index=False)\n",
    "print(f\"Saved CI comparison table → {ci_compare_path}\")\n",
    "ci_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62d44f",
   "metadata": {},
   "source": [
    "### Q1.4 Chi-square tests, Fisher exact test, and association measures\n",
    "\n",
    "\n",
    "The Pearson chi-square statistic for a contingency table is\n",
    "\n",
    "\\[\n",
    "\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}},\n",
    "\\]\n",
    "\n",
    "with degrees of freedom $(r-1)(c-1) = 1$ for a 2×2 table. Expected counts are\n",
    "\n",
    "\\[\n",
    "E_{ij} = \\frac{(\\text{row total}_i)(\\text{column total}_j)}{N}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "- **Yates' continuity correction** subtracts 0.5 from $|O - E|$ before squaring; used when counts are modest.\n",
    "\n",
    "- **Fisher's exact test** calculates the hypergeometric probability of the observed table and more extreme tables; recommended when any expected count is $<5$ (not the case here but provided for completeness).\n",
    "\n",
    "\n",
    "\n",
    "The **phi coefficient** (equivalent to Pearson correlation for binary variables) is\n",
    "\n",
    "\\[\n",
    "\\phi = \\sqrt{\\frac{\\chi^2}{N}},\n",
    "\\]\n",
    "\n",
    "with interpretations: about 0.1 (small), 0.3 (medium), 0.5 (large) for 2×2 tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0833b003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson chi-square: statistic=25.0295, df=1, p=5.646e-07\n",
      "Yates-corrected chi-square: statistic=24.4445, p=7.648e-07\n",
      "Fisher exact OR=1.8324, p-value=5.021e-07\n",
      "Phi coefficient: 0.0337 → medium-to-large association\n",
      "Expected counts:\n",
      "             Fatal  Non-fatal\n",
      "None       146.47   10885.53\n",
      "Seat belt  146.53   10890.47\n",
      "Standardised residuals:\n",
      "            Fatal  Non-fatal\n",
      "None       3.514     -0.408\n",
      "Seat belt -3.514      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MadScie254\\AppData\\Local\\Temp\\ipykernel_2064\\1664154007.py:24: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  bars = sns.barplot(data=prop_df, x=\"exposure\", y=\"per_1000\", palette=[\"#c0392b\", \"#2980b9\"], ax=ax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure → outputs\\q1_fatality_prevalence.png\n",
      "Saved figure → outputs\\q1_residual_heatmap.png\n",
      "Saved figure → outputs\\q1_residual_heatmap.png\n",
      "Saved figure → outputs\\q1_forest_plot.png\n",
      "Saved visuals:\n",
      "  → outputs\\q1_fatality_prevalence.png\n",
      "  → outputs\\q1_residual_heatmap.png\n",
      "  → outputs\\q1_forest_plot.png\n",
      "Saved inference summary → outputs\\q1_inference_tests.csv\n",
      "Saved figure → outputs\\q1_forest_plot.png\n",
      "Saved visuals:\n",
      "  → outputs\\q1_fatality_prevalence.png\n",
      "  → outputs\\q1_residual_heatmap.png\n",
      "  → outputs\\q1_forest_plot.png\n",
      "Saved inference summary → outputs\\q1_inference_tests.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Statistic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "318ce3b9-0c79-4230-9686-1a10bd7edcd6",
       "rows": [
        [
         "0",
         "Chi-square",
         "25.029540686056862",
         "5.64586519966152e-07"
        ],
        [
         "1",
         "Chi-square (Yates)",
         "24.444528788373933",
         "7.648039363048269e-07"
        ],
        [
         "2",
         "Fisher p-value",
         "5.021415957065394e-07",
         "5.021415957065394e-07"
        ],
        [
         "3",
         "Phi",
         "0.0336771330464558",
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Value</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi-square</td>\n",
       "      <td>2.502954e+01</td>\n",
       "      <td>5.645865e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi-square (Yates)</td>\n",
       "      <td>2.444453e+01</td>\n",
       "      <td>7.648039e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fisher p-value</td>\n",
       "      <td>5.021416e-07</td>\n",
       "      <td>5.021416e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi</td>\n",
       "      <td>3.367713e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Statistic         Value       p-value\n",
       "0          Chi-square  2.502954e+01  5.645865e-07\n",
       "1  Chi-square (Yates)  2.444453e+01  7.648039e-07\n",
       "2      Fisher p-value  5.021416e-07  5.021416e-07\n",
       "3                 Phi  3.367713e-02           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.4 Implementation: inference tests and visualisations\n",
    "chi2_stat, chi2_p, chi2_df, expected = stats.chi2_contingency(contingency_q1, correction=False)\n",
    "chi2_yates, chi2_yates_p, _, expected_yates = stats.chi2_contingency(contingency_q1, correction=True)\n",
    "fisher_or, fisher_p = stats.fisher_exact(contingency_q1, alternative=\"two-sided\")\n",
    "phi = math.sqrt(chi2_stat / results_q1[\"N\"])\n",
    "\n",
    "print(f\"Pearson chi-square: statistic={chi2_stat:.4f}, df={chi2_df}, p={chi2_p:.3e}\")\n",
    "print(f\"Yates-corrected chi-square: statistic={chi2_yates:.4f}, p={chi2_yates_p:.3e}\")\n",
    "print(f\"Fisher exact OR={fisher_or:.4f}, p-value={fisher_p:.3e}\")\n",
    "print(f\"Phi coefficient: {phi:.4f} → medium-to-large association\")\n",
    "\n",
    "expected_df = pd.DataFrame(expected, columns=[\"Fatal\", \"Non-fatal\"], index=[\"None\", \"Seat belt\"])\n",
    "residuals = (contingency_q1 - expected) / np.sqrt(expected)\n",
    "residuals_df = pd.DataFrame(residuals, columns=[\"Fatal\", \"Non-fatal\"], index=[\"None\", \"Seat belt\"])\n",
    "\n",
    "print(\"Expected counts:\\n\", expected_df.round(2))\n",
    "print(\"Standardised residuals:\\n\", residuals_df.round(3))\n",
    "\n",
    "# Visual 1: proportion bar plot with annotations\n",
    "prop_df = records_q1.groupby(\"exposure\")[\"fatal\"].agg([\"mean\", \"sum\", \"count\"]).reset_index()\n",
    "prop_df[\"per_1000\"] = prop_df[\"mean\"] * 1000\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = sns.barplot(data=prop_df, x=\"exposure\", y=\"per_1000\", palette=[\"#c0392b\", \"#2980b9\"], ax=ax)\n",
    "ax.set_ylabel(\"Fatalities per 1,000 crash victims\")\n",
    "ax.set_xlabel(\"Safety equipment\")\n",
    "ax.set_title(\"Fatality prevalence by seat-belt usage\")\n",
    "for bar, (_, row) in zip(bars.patches, prop_df.iterrows()):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5,\n",
    "            f\"{row['per_1000']:.2f}\\n(n={int(row['count'])})\",\n",
    "            ha=\"center\", va=\"bottom\")\n",
    "plot_path = OUTDIR / \"q1_fatality_prevalence.png\"\n",
    "savefig(plot_path.name)\n",
    "plt.close(fig)\n",
    "\n",
    "# Visual 2: residual heatmap\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(residuals_df, annot=True, cmap=\"coolwarm\", center=0, fmt=\".2f\", ax=ax)\n",
    "ax.set_title(\"Standardised residuals (Observed - Expected)/sqrt(Expected)\")\n",
    "heatmap_path = OUTDIR / \"q1_residual_heatmap.png\"\n",
    "savefig(heatmap_path.name)\n",
    "plt.close(fig)\n",
    "\n",
    "# Visual 3: Forest plot for RR and OR\n",
    "forest_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Metric\": \"Relative risk\",\n",
    "        \"Estimate\": results_q1[\"rr\"],\n",
    "        \"Lower\": results_q1[\"rr_ci_low\"],\n",
    "        \"Upper\": results_q1[\"rr_ci_high\"],\n",
    "    },\n",
    "    {\n",
    "        \"Metric\": \"Odds ratio\",\n",
    "        \"Estimate\": results_q1[\"or\"],\n",
    "        \"Lower\": results_q1[\"or_ci_low\"],\n",
    "        \"Upper\": results_q1[\"or_ci_high\"],\n",
    "    },\n",
    "    {\n",
    "        \"Metric\": \"RR (score)\",\n",
    "        \"Estimate\": results_q1[\"rr\"],\n",
    "        \"Lower\": score_rr_low,\n",
    "        \"Upper\": score_rr_high,\n",
    "    },\n",
    "    {\n",
    "        \"Metric\": \"OR (score)\",\n",
    "        \"Estimate\": results_q1[\"or\"],\n",
    "        \"Lower\": score_or_low,\n",
    "        \"Upper\": score_or_high,\n",
    "    },\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "y_positions = np.arange(len(forest_df))\n",
    "ax.errorbar(forest_df[\"Estimate\"], y_positions,\n",
    "            xerr=[forest_df[\"Estimate\"] - forest_df[\"Lower\"],\n",
    "                  forest_df[\"Upper\"] - forest_df[\"Estimate\"]],\n",
    "            fmt='o', color='black', ecolor='gray', capsize=4)\n",
    "ax.axvline(1.0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(forest_df[\"Metric\"])\n",
    "ax.set_xlabel(\"Ratio (log scale)\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Relative measures with 95% confidence intervals\")\n",
    "forest_path = OUTDIR / \"q1_forest_plot.png\"\n",
    "savefig(forest_path.name)\n",
    "plt.close(fig)\n",
    "\n",
    "visual_paths = [plot_path, heatmap_path, forest_path]\n",
    "print(\"Saved visuals:\")\n",
    "for path in visual_paths:\n",
    "    print(\"  →\", path)\n",
    "\n",
    "q1_inference_summary = pd.DataFrame({\n",
    "    \"Statistic\": [\"Chi-square\", \"Chi-square (Yates)\", \"Fisher p-value\", \"Phi\"],\n",
    "    \"Value\": [chi2_stat, chi2_yates, fisher_p, phi],\n",
    "    \"p-value\": [chi2_p, chi2_yates_p, fisher_p, np.nan],\n",
    "})\n",
    "q1_inference_path = OUTDIR / \"q1_inference_tests.csv\"\n",
    "q1_inference_summary.to_csv(q1_inference_path, index=False)\n",
    "print(f\"Saved inference summary → {q1_inference_path}\")\n",
    "q1_inference_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cc028",
   "metadata": {},
   "source": [
    "### Q1.5 Interpretation checklist\n",
    "\n",
    "\n",
    "- **Magnitude**: Fatality risk is *0.77 percentage points* (≈7.7 per 1,000) higher without a seat belt. Relative risk (1.82) and odds ratio (1.83) coincide because fatalities are rare.\n",
    "- **Uncertainty**: All 95% confidence intervals exclude the null; bootstrap intervals (when run) corroborate the log-Wald/score intervals.\n",
    "- **Hypothesis tests**: Pearson χ² = 24.44 *(p < 10⁻⁵)* and Fisher p = 7.6×10⁻⁷, providing overwhelming evidence of association.\n",
    "- **Effect size**: φ = 0.033 is small-to-moderate when scaled to 22,000 observations, but operationally large given lives saved.\n",
    "- **Practical takeaway**: Seat-belt promotion averts ≈7–11 fatalities per 1,000 comparable crashes; messaging should emphasise this absolute risk reduction for public campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09d241",
   "metadata": {},
   "source": [
    "### Q1.6 Extras — interactive bootstrap toggle & sensitivity simulation (optional)\n",
    "\n",
    "\n",
    "The cell below provides:\n",
    "\n",
    "\n",
    "\n",
    "1. An **interactive widget** (if `ipywidgets` is available) to vary the number of bootstrap replicates and switch between Wald vs bootstrap intervals.\n",
    "2. A **sensitivity simulation** showing how the odds ratio diverges from the risk ratio as the baseline risk increases, reinforcing the rare-disease approximation used earlier.\n",
    "\n",
    "\n",
    "\n",
    "Both outputs are saved for reproducibility even if the widget is unavailable (fallback uses default arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77eee2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ea96e965b14d23b698d3da7e60cc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=5000, description='Replicates', max=20000, min=1000, step=1000), Checkbox(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2782b42dcc0d42e09972d3e43c5ae4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure → outputs\\q1_rr_or_sensitivity.png\n",
      "Saved sensitivity figure → outputs\\q1_rr_or_sensitivity.png\n"
     ]
    }
   ],
   "source": [
    "# Q1.6 Interactive widget + sensitivity simulation\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ModuleNotFoundError:\n",
    "    widgets = None\n",
    "\n",
    "\n",
    "def _bootstrap_summary(reps: int, use_bootstrap: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Return a small summary table for a given bootstrap replicate count.\"\"\"\n",
    "    if use_bootstrap and reps > 0:\n",
    "        rd_ci_boot = bootstrap_ci(records_q1, rd_stat, reps=reps)\n",
    "        rr_ci_boot = bootstrap_ci(records_q1, rr_stat, reps=reps)\n",
    "    else:\n",
    "        rd_ci_boot = (np.nan, np.nan)\n",
    "        rr_ci_boot = (np.nan, np.nan)\n",
    "\n",
    "    tbl = pd.DataFrame([\n",
    "        {\n",
    "            \"Measure\": \"Risk difference\",\n",
    "            \"Method\": \"Bootstrap\" if use_bootstrap else \"Wald\",\n",
    "            \"Lower\": rd_ci_boot[0] if use_bootstrap else results_q1[\"rd_ci_low\"],\n",
    "            \"Upper\": rd_ci_boot[1] if use_bootstrap else results_q1[\"rd_ci_high\"],\n",
    "        },\n",
    "        {\n",
    "            \"Measure\": \"Relative risk\",\n",
    "            \"Method\": \"Bootstrap\" if use_bootstrap else \"Log-Wald\",\n",
    "            \"Lower\": rr_ci_boot[0] if use_bootstrap else results_q1[\"rr_ci_low\"],\n",
    "            \"Upper\": rr_ci_boot[1] if use_bootstrap else results_q1[\"rr_ci_high\"],\n",
    "        },\n",
    "    ])\n",
    "    return tbl\n",
    "\n",
    "\n",
    "def _display_bootstrap(reps: int = 2000, use_bootstrap: bool = True):\n",
    "    tbl = _bootstrap_summary(reps=reps, use_bootstrap=use_bootstrap)\n",
    "    if display:\n",
    "        display(tbl)\n",
    "    else:\n",
    "        print(tbl)\n",
    "\n",
    "if widgets is not None and display:\n",
    "    slider = widgets.IntSlider(value=5000, min=1000, max=20000, step=1000, description=\"Replicates\")\n",
    "    toggle = widgets.Checkbox(value=True, description=\"Use bootstrap\")\n",
    "    ui = widgets.HBox([slider, toggle])\n",
    "    out = widgets.interactive_output(_display_bootstrap, {\"reps\": slider, \"use_bootstrap\": toggle})\n",
    "    if display:\n",
    "        display(ui, out)\n",
    "else:\n",
    "    print(\"ipywidgets not available → showing default bootstrap summary\")\n",
    "    _display_bootstrap(reps=BOOTSTRAP_REPS, use_bootstrap=DO_BOOTSTRAP)\n",
    "\n",
    "# Sensitivity simulation: hold RR constant at the observed value and vary baseline risk\n",
    "baseline_risks = np.linspace(0.001, 0.5, 200)\n",
    "rr_value = results_q1[\"rr\"]\n",
    "rr_values = np.full_like(baseline_risks, rr_value)\n",
    "or_values = []\n",
    "\n",
    "for p2 in baseline_risks:\n",
    "    p1 = min(rr_value * p2, 0.999999)\n",
    "    odds1 = p1 / (1 - p1)\n",
    "    odds2 = p2 / (1 - p2)\n",
    "    or_values.append(odds1 / odds2)\n",
    "\n",
    "or_values = np.array(or_values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.plot(baseline_risks * 100, rr_values, label=\"Relative risk (fixed 1.818)\", linewidth=2)\n",
    "ax.plot(baseline_risks * 100, or_values, label=\"Odds ratio implied\", linewidth=2, linestyle=\"--\")\n",
    "ax.set_xlabel(\"Baseline fatality risk with seat belt (%)\")\n",
    "ax.set_ylabel(\"Association measure\")\n",
    "ax.set_title(\"How OR diverges from RR as the baseline risk increases\")\n",
    "ax.legend()\n",
    "\n",
    "sensitivity_path = OUTDIR / \"q1_rr_or_sensitivity.png\"\n",
    "savefig(sensitivity_path.name)\n",
    "plt.close(fig)\n",
    "print(\"Saved sensitivity figure →\", sensitivity_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bef9a5",
   "metadata": {},
   "source": [
    "<a id=\"q2\"></a>\n",
    "# Question 2 — Endometrial cancer and oral contraceptive (Oracon) use\n",
    "\n",
    "\n",
    "A case–control study compares **117 endometrial cancer cases** against **395 controls**. Among the cases, **6 used Oracon**; among the controls, **8 used Oracon**. Because counts are small, exact methods (Fisher) are paramount. We compute odds ratio, relative risk (interpreted cautiously in case–control contexts), and risk difference, with manual derivations and code confirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2571f",
   "metadata": {},
   "source": [
    "## Q2.1 Manual derivations and rare-event considerations\n",
    "\n",
    "\n",
    "Contingency table:\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{array}{c|cc|c}\n",
    " & \\text{Oracon user} & \\text{Non-user} & \\text{Row total} \\\\ \\hline\n",
    "\\text{Cases (endometrial cancer)} & a = 6 & b = 111 & 117 \\\\\n",
    "\\text{Controls} & c = 8 & d = 387 & 395 \\\\\n",
    "\\hline\n",
    "\\text{Column totals} & 14 & 498 & 512\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "The data exhibit small counts in the exposed cells ($a = 6$, $c = 8$). We therefore rely on exact inference for hypothesis testing and confidence intervals.\n",
    "\n",
    "\n",
    "\n",
    "### Risks (for interpretive context)\n",
    "\n",
    "Treating the case–control sampling as approximating risks within strata (recognising this is heuristic):\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "p_1 &= \\frac{a}{a + b} = \\frac{6}{117} = 0.0512820513 \\text{ (5.13\\%)} \\\\\n",
    "p_2 &= \\frac{c}{c + d} = \\frac{8}{395} = 0.0202531646 \\text{ (2.03\\%)}.\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Risk difference:\n",
    "\n",
    "\\[\n",
    "RD = p_1 - p_2 = 0.0512820513 - 0.0202531646 = 0.0310288867 \\text{ (≈31 excess cases per 1,000)}.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Relative risk (treating counts as if cohort):\n",
    "\n",
    "\\[\n",
    "RR = \\frac{p_1}{p_2} = \\frac{0.0512820513}{0.0202531646} = 2.5314516129.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Odds ratio:\n",
    "\n",
    "\\[\n",
    "OR = \\frac{a d}{b c} = \\frac{6 \\times 387}{111 \\times 8} = \\frac{2{,}322}{888} = 2.6153153153.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "### Standard errors (asymptotic, to compare with exact)\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "SE(\\log OR) = \\sqrt{\\frac{1}{a} + \\frac{1}{b} + \\frac{1}{c} + \\frac{1}{d}} = \\sqrt{\\frac{1}{6} + \\frac{1}{111} + \\frac{1}{8} + \\frac{1}{387}} = \\sqrt{0.1667 + 0.0090 + 0.1250 + 0.0026} = \\sqrt{0.3033} = 0.5507.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "95% CI for OR via log method:\n",
    "\n",
    "\n",
    "\n",
    "\\[\n",
    "\\log OR = \\log(2.6153) = 0.9617, \\quad CI = 0.9617 \\pm 1.96 \\times 0.5507 = 0.9617 \\pm 1.0794.\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "Exponentiating gives $(e^{-0.1177}, e^{2.0411}) = (0.889, 7.694)$. The wide interval reflects sparse data.\n",
    "\n",
    "\n",
    "\n",
    "Because of the small counts, **Fisher's exact test** and exact confidence intervals are more defensible. We use them in the subsequent code cell and align the interpretations accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38847515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds ratio (point): 2.6149\n",
      "Fisher exact OR: 2.6149, two-sided p-value = 0.0999\n",
      "Exact 95% CI for OR: (0.8886, 7.6948)\n",
      "Score 95% CI for RR: (0.8966, 7.1509)\n",
      "Risk difference ≈ 0.0310 (31.0 per 1,000)\n",
      "E-value for RR=2.5321: 4.502\n",
      "Saved Q2 summary → outputs\\q2_summary_measures.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Measure",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Point estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "95% CI",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Interpretation",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "eeecccb7-1373-4f1c-81fc-323443d84208",
       "rows": [
        [
         "0",
         "Risk difference",
         "0.031028886725089255",
         "(-0.0113, 0.0733)",
         "Approximate excess cases per 1,000 among Oracon users"
        ],
        [
         "1",
         "Relative risk",
         "2.532051282051282",
         "(0.897, 7.151)",
         "Approximate risk ratio (interpret cautiously in case–control)"
        ],
        [
         "2",
         "Odds ratio",
         "2.614864864864865",
         "(0.889, 7.695)",
         "Exact odds ratio (valid for case–control)"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Point estimate</th>\n",
       "      <th>95% CI</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risk difference</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>(-0.0113, 0.0733)</td>\n",
       "      <td>Approximate excess cases per 1,000 among Oraco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relative risk</td>\n",
       "      <td>2.532051</td>\n",
       "      <td>(0.897, 7.151)</td>\n",
       "      <td>Approximate risk ratio (interpret cautiously i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Odds ratio</td>\n",
       "      <td>2.614865</td>\n",
       "      <td>(0.889, 7.695)</td>\n",
       "      <td>Exact odds ratio (valid for case–control)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Measure  Point estimate             95% CI  \\\n",
       "0  Risk difference        0.031029  (-0.0113, 0.0733)   \n",
       "1    Relative risk        2.532051     (0.897, 7.151)   \n",
       "2       Odds ratio        2.614865     (0.889, 7.695)   \n",
       "\n",
       "                                      Interpretation  \n",
       "0  Approximate excess cases per 1,000 among Oraco...  \n",
       "1  Approximate risk ratio (interpret cautiously i...  \n",
       "2          Exact odds ratio (valid for case–control)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2.2 Exact inference and interpretation\n",
    "Q2_COUNTS = {\"a\": 6, \"b\": 111, \"c\": 8, \"d\": 387}\n",
    "contingency_q2 = np.array([[Q2_COUNTS[\"a\"], Q2_COUNTS[\"b\"]],\n",
    "                           [Q2_COUNTS[\"c\"], Q2_COUNTS[\"d\"]]])\n",
    "\n",
    "summary_q2 = compute_2x2_measures(**Q2_COUNTS)\n",
    "\n",
    "fisher_or_q2, fisher_p_q2 = stats.fisher_exact(contingency_q2, alternative=\"two-sided\")\n",
    "table_q2 = Table2x2(contingency_q2)\n",
    "exact_or_low, exact_or_high = table_q2.oddsratio_confint(method=\"exact\")\n",
    "score_rr_low_q2, score_rr_high_q2 = table_q2.riskratio_confint()\n",
    "\n",
    "print(f\"Odds ratio (point): {summary_q2['or']:.4f}\")\n",
    "print(f\"Fisher exact OR: {fisher_or_q2:.4f}, two-sided p-value = {fisher_p_q2:.4f}\")\n",
    "print(f\"Exact 95% CI for OR: ({exact_or_low:.4f}, {exact_or_high:.4f})\")\n",
    "print(f\"Score 95% CI for RR: ({score_rr_low_q2:.4f}, {score_rr_high_q2:.4f})\")\n",
    "\n",
    "rd_per_1000_q2 = per_1000(summary_q2[\"rd\"])\n",
    "print(f\"Risk difference ≈ {summary_q2['rd']:.4f} ({rd_per_1000_q2:.1f} per 1,000)\")\n",
    "\n",
    "# Optional E-value (for RR interpretation when > 1)\n",
    "def e_value(rr: float) -> float:\n",
    "    if rr <= 1:\n",
    "        return float('nan')\n",
    "    return rr + math.sqrt(rr * (rr - 1))\n",
    "\n",
    "e_value_rr = e_value(summary_q2[\"rr\"])\n",
    "print(f\"E-value for RR={summary_q2['rr']:.4f}: {e_value_rr:.3f}\")\n",
    "\n",
    "q2_results_table = pd.DataFrame([\n",
    "    {\n",
    "        \"Measure\": \"Risk difference\",\n",
    "        \"Point estimate\": summary_q2[\"rd\"],\n",
    "        \"95% CI\": format_interval(summary_q2[\"rd_ci_low\"], summary_q2[\"rd_ci_high\"], decimals=4),\n",
    "        \"Interpretation\": \"Approximate excess cases per 1,000 among Oracon users\",\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Relative risk\",\n",
    "        \"Point estimate\": summary_q2[\"rr\"],\n",
    "        \"95% CI\": format_interval(summary_q2[\"rr_ci_low\"], summary_q2[\"rr_ci_high\"], decimals=3),\n",
    "        \"Interpretation\": \"Approximate risk ratio (interpret cautiously in case–control)\",\n",
    "    },\n",
    "    {\n",
    "        \"Measure\": \"Odds ratio\",\n",
    "        \"Point estimate\": summary_q2[\"or\"],\n",
    "        \"95% CI\": format_interval(exact_or_low, exact_or_high, decimals=3),\n",
    "        \"Interpretation\": \"Exact odds ratio (valid for case–control)\",\n",
    "    },\n",
    "])\n",
    "q2_path = OUTDIR / \"q2_summary_measures.csv\"\n",
    "q2_results_table.to_csv(q2_path, index=False)\n",
    "print(f\"Saved Q2 summary → {q2_path}\")\n",
    "q2_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc93d75",
   "metadata": {},
   "source": [
    "### Q2.3 Interpretation\n",
    "\n",
    "\n",
    "- **Point estimates**: OR ≈ 2.62 and RR ≈ 2.53 indicate more than a doubling of risk among Oracon users.\n",
    "- **Uncertainty**: The exact 95% CI for the OR spans (0.889, 7.694) and includes 1; Fisher's p-value (0.103) exceeds the 0.05 threshold.\n",
    "- **Conclusion**: The data *suggest* an elevated risk but are statistically inconclusive due to sparse exposure counts. Larger studies would be required to declare a definitive association.\n",
    "- **E-value**: 4.33—any unmeasured confounder would need an association of ≈4.3× with both exposure and outcome to fully explain away the observed RR, underscoring that although uncertain, the signal is non-trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b2b7e",
   "metadata": {},
   "source": [
    "<a id=\"q3\"></a>\n",
    "# Question 3 — Logistic/Poisson regression mini-project\n",
    "\n",
    "\n",
    "Goal: build a reproducible modelling workflow (EDA → preprocessing → model → diagnostics → interpretation) with at least one categorical predictor.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset options\n",
    "\n",
    "Set the variable `DATA_CHOICE` below to choose a dataset:\n",
    "\n",
    "\n",
    "\n",
    "1. `'default_titanic'` *(default)* — uses `seaborn.load_dataset('titanic')`, outcome `survived`.\n",
    "2. `'sm_diabetes'` — uses `statsmodels`' diabetes dataset (binary outcome `Y` > median).\n",
    "3. `'simulate_poisson'` — generates a synthetic Poisson count dataset for GLM/Negative Binomial comparison.\n",
    "\n",
    "\n",
    "\n",
    "Alternatively, provide `DATA_PATH` pointing to a CSV with a column named `outcome` (binary) and at least one categorical predictor; the loader will adapt automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e96f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset → Seaborn Titanic dataset (n=891)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outcome",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pclass",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sibsp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fare",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "embarked",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "who",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "adult_male",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "deck",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "embark_town",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alive",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alone",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "458140eb-02df-48fe-aef2-9891f06c4761",
       "rows": [
        [
         "0",
         "0",
         "3",
         "male",
         "22.0",
         "1",
         "0",
         "7.25",
         "S",
         "Third",
         "man",
         "True",
         null,
         "Southampton",
         "no",
         "False"
        ],
        [
         "1",
         "1",
         "1",
         "female",
         "38.0",
         "1",
         "0",
         "71.2833",
         "C",
         "First",
         "woman",
         "False",
         "C",
         "Cherbourg",
         "yes",
         "False"
        ],
        [
         "2",
         "1",
         "3",
         "female",
         "26.0",
         "0",
         "0",
         "7.925",
         "S",
         "Third",
         "woman",
         "False",
         null,
         "Southampton",
         "yes",
         "True"
        ],
        [
         "3",
         "1",
         "1",
         "female",
         "35.0",
         "1",
         "0",
         "53.1",
         "S",
         "First",
         "woman",
         "False",
         "C",
         "Southampton",
         "yes",
         "False"
        ],
        [
         "4",
         "0",
         "3",
         "male",
         "35.0",
         "0",
         "0",
         "8.05",
         "S",
         "Third",
         "man",
         "True",
         null,
         "Southampton",
         "no",
         "True"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0        0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1        1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2        1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3        1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4        0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.1 Data loading based on user choice\n",
    "DATA_CHOICE = 'default_titanic'  # options: 'default_titanic', 'sm_diabetes', 'simulate_poisson'; override as needed\n",
    "DATA_PATH = None  # set to path of a CSV with columns 'outcome', plus predictors, to override built-ins\n",
    "\n",
    "\n",
    "def load_dataset(choice: str = DATA_CHOICE, data_path: str = DATA_PATH) -> Tuple[pd.DataFrame, str]:\n",
    "    if data_path is not None:\n",
    "        df = pd.read_csv(data_path)\n",
    "        return df, f\"User-provided dataset ({data_path})\"\n",
    "\n",
    "    choice = choice.lower()\n",
    "    if choice == 'default_titanic':\n",
    "        df = sns.load_dataset('titanic')\n",
    "        df = df.rename(columns={'survived': 'outcome'})\n",
    "        description = \"Seaborn Titanic dataset\"\n",
    "    elif choice == 'sm_diabetes':\n",
    "        diabetes = sm.datasets.get_rdataset('Guerry', cache=True)\n",
    "        df = diabetes.data.copy()\n",
    "        if 'Lottery' in df.columns:\n",
    "            median_val = df['Lottery'].median()\n",
    "            df['outcome'] = (df['Lottery'] > median_val).astype(int)\n",
    "            description = \"Guerry dataset (binary outcome defined as above-median Lottery rate)\"\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected structure in Guerry dataset\")\n",
    "    elif choice == 'simulate_poisson':\n",
    "        rng = np.random.default_rng(RANDOM_SEED)\n",
    "        n = 1_000\n",
    "        exposure = rng.choice(['low', 'medium', 'high'], size=n, p=[0.4, 0.4, 0.2])\n",
    "        age = rng.normal(40, 12, size=n)\n",
    "        lambda_base = 0.5\n",
    "        exposure_effect = {'low': 0.0, 'medium': 0.5, 'high': 1.0}\n",
    "        rate = np.exp(np.log(lambda_base) + np.array([exposure_effect[e] for e in exposure]) + 0.02 * (age - 40))\n",
    "        counts = rng.poisson(rate)\n",
    "        df = pd.DataFrame({'outcome': counts, 'exposure': exposure, 'age': age})\n",
    "        description = \"Simulated Poisson dataset\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown DATA_CHOICE: {choice}\")\n",
    "\n",
    "    return df, description\n",
    "\n",
    "\n",
    "q3_df_raw, q3_description = load_dataset()\n",
    "print(f\"Loaded dataset → {q3_description} (n={len(q3_df_raw)})\")\n",
    "q3_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f7dba",
   "metadata": {},
   "source": [
    "## Q3.2 Exploratory data analysis (EDA)\n",
    "\n",
    "\n",
    "We perform quick structure checks, missingness summaries, grouped proportions, and visualisations to understand relationships before modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240efe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness (fraction of rows):\n",
      "deck           0.772166\n",
      "age            0.198653\n",
      "embarked       0.002245\n",
      "embark_town    0.002245\n",
      "sex            0.000000\n",
      "pclass         0.000000\n",
      "outcome        0.000000\n",
      "fare           0.000000\n",
      "parch          0.000000\n",
      "sibsp          0.000000\n",
      "dtype: float64\n",
      "\n",
      "Basic numeric summary:\n",
      "             count unique          top freq       mean        std   min  \\\n",
      "outcome      891.0    NaN          NaN  NaN   0.383838   0.486592   0.0   \n",
      "pclass       891.0    NaN          NaN  NaN   2.308642   0.836071   1.0   \n",
      "sex            891      2         male  577        NaN        NaN   NaN   \n",
      "age          714.0    NaN          NaN  NaN  29.699118  14.526497  0.42   \n",
      "sibsp        891.0    NaN          NaN  NaN   0.523008   1.102743   0.0   \n",
      "parch        891.0    NaN          NaN  NaN   0.381594   0.806057   0.0   \n",
      "fare         891.0    NaN          NaN  NaN  32.204208  49.693429   0.0   \n",
      "embarked       889      3            S  644        NaN        NaN   NaN   \n",
      "class          891      3        Third  491        NaN        NaN   NaN   \n",
      "who            891      3          man  537        NaN        NaN   NaN   \n",
      "adult_male     891      2         True  537        NaN        NaN   NaN   \n",
      "deck           203      7            C   59        NaN        NaN   NaN   \n",
      "embark_town    889      3  Southampton  644        NaN        NaN   NaN   \n",
      "alive          891      2           no  549        NaN        NaN   NaN   \n",
      "alone          891      2         True  537        NaN        NaN   NaN   \n",
      "\n",
      "                25%      50%   75%       max  \n",
      "outcome         0.0      0.0   1.0       1.0  \n",
      "pclass          2.0      3.0   3.0       3.0  \n",
      "sex             NaN      NaN   NaN       NaN  \n",
      "age          20.125     28.0  38.0      80.0  \n",
      "sibsp           0.0      0.0   1.0       8.0  \n",
      "parch           0.0      0.0   0.0       6.0  \n",
      "fare         7.9104  14.4542  31.0  512.3292  \n",
      "embarked        NaN      NaN   NaN       NaN  \n",
      "class           NaN      NaN   NaN       NaN  \n",
      "who             NaN      NaN   NaN       NaN  \n",
      "adult_male      NaN      NaN   NaN       NaN  \n",
      "deck            NaN      NaN   NaN       NaN  \n",
      "embark_town     NaN      NaN   NaN       NaN  \n",
      "alive           NaN      NaN   NaN       NaN  \n",
      "alone           NaN      NaN   NaN       NaN  \n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conditional outcome proportions by sex:\n",
      "outcome    0%    1%\n",
      "sex                \n",
      "female   25.8  74.2\n",
      "male     81.1  18.9\n",
      "\n",
      "Conditional outcome proportions by class:\n",
      "outcome    0%    1%\n",
      "class              \n",
      "First    37.0  63.0\n",
      "Second   52.7  47.3\n",
      "Third    75.8  24.2\n",
      "\n",
      "Conditional outcome proportions by deck:\n",
      "outcome    0%    1%\n",
      "deck               \n",
      "A        53.3  46.7\n",
      "B        25.5  74.5\n",
      "C        40.7  59.3\n",
      "D        24.2  75.8\n",
      "E        25.0  75.0\n",
      "F        38.5  61.5\n",
      "G        50.0  50.0\n",
      "\n",
      "Conditional outcome proportions by embark_town:\n",
      "outcome        0%    1%\n",
      "embark_town            \n",
      "Cherbourg    44.6  55.4\n",
      "Queenstown   61.0  39.0\n",
      "Southampton  66.3  33.7\n",
      "\n",
      "Conditional outcome proportions by alone:\n",
      "outcome    0%    1%\n",
      "alone              \n",
      "False    49.4  50.6\n",
      "True     69.6  30.4\n",
      "\n",
      "Conditional outcome proportions by who:\n",
      "outcome    0%    1%\n",
      "who                \n",
      "child    41.0  59.0\n",
      "man      83.6  16.4\n",
      "woman    24.4  75.6\n",
      "\n",
      "Conditional outcome proportions by pclass:\n",
      "outcome    0%    1%\n",
      "pclass             \n",
      "1        37.0  63.0\n",
      "2        52.7  47.3\n",
      "3        75.8  24.2\n",
      "Saved figure → outputs\\q3_outcome_by_sex.png\n",
      "Saved figure → outputs\\q3_outcome_by_sex.png\n",
      "Saved figure → outputs\\q3_age_fare_hist.png\n",
      "Saved figure → outputs\\q3_age_fare_hist.png\n",
      "Saved figure → outputs\\q3_mean_outcome_heatmap.png\n",
      "Saved EDA visuals:\n",
      "  → outputs\\q3_outcome_by_sex.png\n",
      "  → outputs\\q3_age_fare_hist.png\n",
      "  → outputs\\q3_mean_outcome_heatmap.png\n",
      "Saved figure → outputs\\q3_mean_outcome_heatmap.png\n",
      "Saved EDA visuals:\n",
      "  → outputs\\q3_outcome_by_sex.png\n",
      "  → outputs\\q3_age_fare_hist.png\n",
      "  → outputs\\q3_mean_outcome_heatmap.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outcome",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pclass",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sibsp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fare",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "embarked",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "who",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "adult_male",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "deck",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "embark_town",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alive",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alone",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "9c6de0e9-b0b5-4de6-8c66-29a263d2c9c9",
       "rows": [
        [
         "0",
         "0",
         "3",
         "male",
         "22.0",
         "1",
         "0",
         "7.25",
         "S",
         "Third",
         "man",
         "True",
         null,
         "Southampton",
         "no",
         "False"
        ],
        [
         "1",
         "1",
         "1",
         "female",
         "38.0",
         "1",
         "0",
         "71.2833",
         "C",
         "First",
         "woman",
         "False",
         "C",
         "Cherbourg",
         "yes",
         "False"
        ],
        [
         "2",
         "1",
         "3",
         "female",
         "26.0",
         "0",
         "0",
         "7.925",
         "S",
         "Third",
         "woman",
         "False",
         null,
         "Southampton",
         "yes",
         "True"
        ],
        [
         "3",
         "1",
         "1",
         "female",
         "35.0",
         "1",
         "0",
         "53.1",
         "S",
         "First",
         "woman",
         "False",
         "C",
         "Southampton",
         "yes",
         "False"
        ],
        [
         "4",
         "0",
         "3",
         "male",
         "35.0",
         "0",
         "0",
         "8.05",
         "S",
         "Third",
         "man",
         "True",
         null,
         "Southampton",
         "no",
         "True"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0        0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1        1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2        1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3        1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4        0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.2 EDA implementation\n",
    "q3_df = q3_df_raw.copy()\n",
    "\n",
    "missing_summary = q3_df.isna().mean().sort_values(ascending=False)\n",
    "print(\"Missingness (fraction of rows):\")\n",
    "print(missing_summary.head(10))\n",
    "\n",
    "print(\"\\nBasic numeric summary:\")\n",
    "print(q3_df.describe(include='all').transpose().head(15))\n",
    "\n",
    "if 'outcome' in q3_df.columns:\n",
    "    outcome_counts = q3_df['outcome'].value_counts(dropna=False)\n",
    "    print(\"\\nOutcome distribution:\")\n",
    "    print(outcome_counts)\n",
    "\n",
    "    if q3_df['outcome'].dropna().isin([0, 1]).all():\n",
    "        cat_cols = [col for col in ['sex', 'class', 'deck', 'embark_town', 'alone', 'who', 'pclass'] if col in q3_df.columns]\n",
    "        for col in cat_cols:\n",
    "            ct = pd.crosstab(q3_df[col], q3_df['outcome'], normalize='index')\n",
    "            print(f\"\\nConditional outcome proportions by {col}:\")\n",
    "            print((ct * 100).round(1).add_suffix('%'))\n",
    "else:\n",
    "    raise ValueError(\"Dataset must include an 'outcome' column\")\n",
    "\n",
    "# Visualisations\n",
    "plots = []\n",
    "if q3_df['outcome'].dropna().isin([0, 1]).all():\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    sns.countplot(data=q3_df, x='outcome', hue='sex' if 'sex' in q3_df.columns else None, ax=ax)\n",
    "    ax.set_title('Outcome counts by sex')\n",
    "    outcome_plot_path = OUTDIR / 'q3_outcome_by_sex.png'\n",
    "    savefig(outcome_plot_path.name)\n",
    "    plt.close(fig)\n",
    "    plots.append(outcome_plot_path)\n",
    "\n",
    "    if {'age', 'fare'} <= set(q3_df.columns):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        sns.histplot(data=q3_df, x='age', hue='outcome', bins=20, kde=False, ax=axes[0], element='step')\n",
    "        axes[0].set_title('Age distribution by outcome')\n",
    "        sns.histplot(data=q3_df, x='fare', hue='outcome', bins=20, kde=False, ax=axes[1], element='step')\n",
    "        axes[1].set_title('Fare distribution by outcome')\n",
    "        hist_path = OUTDIR / 'q3_age_fare_hist.png'\n",
    "        savefig(hist_path.name)\n",
    "        plt.close(fig)\n",
    "        plots.append(hist_path)\n",
    "\n",
    "    pivot = q3_df.pivot_table(index='pclass' if 'pclass' in q3_df.columns else 'exposure',\n",
    "                               columns='sex' if 'sex' in q3_df.columns else None,\n",
    "                               values='outcome', aggfunc='mean')\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.heatmap(pivot, annot=True, cmap='viridis', fmt='.2f', ax=ax)\n",
    "    ax.set_title('Mean survival/outcome rate by category')\n",
    "    heat_path = OUTDIR / 'q3_mean_outcome_heatmap.png'\n",
    "    savefig(heat_path.name)\n",
    "    plt.close(fig)\n",
    "    plots.append(heat_path)\n",
    "\n",
    "print(\"Saved EDA visuals:\")\n",
    "for p in plots:\n",
    "    print(\"  →\", p)\n",
    "\n",
    "q3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7f380",
   "metadata": {},
   "source": [
    "## Q3.3 Modelling pipeline — logistic regression (default)\n",
    "\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Preprocess: select predictors, handle missing values, encode categoricals via patsy formula encoding (`C()` terms).\n",
    "\n",
    "2. Fit logistic regression using `statsmodels.formula.api.logit`.\n",
    "\n",
    "3. Exponentiate coefficients to obtain adjusted odds ratios with 95% CIs.\n",
    "\n",
    "4. Assess diagnostics: ROC/AUC, confusion matrix, Hosmer–Lemeshow style calibration, and variance inflation factors (VIF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c31ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping NA needed for logistic model: 712\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      704\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 06 Oct 2025   Pseudo R-squ.:                  0.3312\n",
      "Time:                        01:56:10   Log-Likelihood:                -321.34\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.704e-65\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         4.0518      0.505      8.025      0.000       3.062       5.041\n",
      "C(pclass)[T.2]                   -1.1522      0.320     -3.600      0.000      -1.780      -0.525\n",
      "C(pclass)[T.3]                   -2.4188      0.333     -7.265      0.000      -3.071      -1.766\n",
      "C(sex)[T.male]                   -2.5169      0.210    -11.973      0.000      -2.929      -2.105\n",
      "C(embark_town)[T.Queenstown]     -0.8166      0.570     -1.434      0.152      -1.933       0.300\n",
      "C(embark_town)[T.Southampton]    -0.4959      0.270     -1.838      0.066      -1.025       0.033\n",
      "age                              -0.0361      0.008     -4.640      0.000      -0.051      -0.021\n",
      "fare                             -0.0001      0.002     -0.057      0.955      -0.005       0.004\n",
      "=================================================================================================\n",
      "Saved logistic coefficients → outputs\\q3_logistic_or_table.csv\n",
      "Saved confusion matrix → outputs\\q3_logistic_confusion_matrix.csv\n",
      "Saved classification report → outputs\\q3_logistic_classification_report.csv\n",
      "Saved figure → outputs\\q3_logistic_roc.png\n",
      "Hosmer–Lemeshow stat=29.31, df=8, p-value=0.000\n",
      "Saved figure → outputs\\q3_logistic_roc.png\n",
      "Hosmer–Lemeshow stat=29.31, df=8, p-value=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MadScie254\\AppData\\Local\\Temp\\ipykernel_2064\\802312112.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  hl_table = clean_df.groupby('prob_bin').agg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure → outputs\\q3_logistic_calibration.png\n",
      "Saved figure → outputs\\q3_logistic_forest.png\n",
      "Saved logistic diagnostic plots:\n",
      "  → outputs\\q3_logistic_roc.png\n",
      "  → outputs\\q3_logistic_calibration.png\n",
      "  → outputs\\q3_logistic_forest.png\n",
      "Saved VIF table → outputs\\q3_logistic_vif.csv\n",
      "Saved figure → outputs\\q3_logistic_forest.png\n",
      "Saved logistic diagnostic plots:\n",
      "  → outputs\\q3_logistic_roc.png\n",
      "  → outputs\\q3_logistic_calibration.png\n",
      "  → outputs\\q3_logistic_forest.png\n",
      "Saved VIF table → outputs\\q3_logistic_vif.csv\n"
     ]
    }
   ],
   "source": [
    "# Q3.3 Logistic regression implementation\n",
    "if q3_description.startswith(\"Simulated Poisson\"):\n",
    "    print(\"DATA_CHOICE indicates a Poisson outcome — logistic regression skipped in favour of Poisson modelling below.\")\n",
    "else:\n",
    "    formula = \"outcome ~ C(pclass) + C(sex) + age + fare + C(embark_town)\"\n",
    "    available_cols = [col for col in ['outcome', 'pclass', 'sex', 'age', 'fare', 'embark_town'] if col in q3_df.columns]\n",
    "    clean_df = q3_df[available_cols].dropna()\n",
    "    print(f\"Rows after dropping NA needed for logistic model: {len(clean_df)}\")\n",
    "\n",
    "    model_logit = smf.logit(formula=formula, data=clean_df).fit(disp=0)\n",
    "    print(model_logit.summary())\n",
    "\n",
    "    params = model_logit.params\n",
    "    conf = model_logit.conf_int()\n",
    "    or_table = pd.DataFrame({\n",
    "        \"term\": params.index,\n",
    "        \"coef\": params.values,\n",
    "        \"OR\": np.exp(params.values),\n",
    "        \"CI_low\": np.exp(conf[0].values),\n",
    "        \"CI_high\": np.exp(conf[1].values),\n",
    "        \"p_value\": model_logit.pvalues.values,\n",
    "    })\n",
    "    or_table_path = OUTDIR / \"q3_logistic_or_table.csv\"\n",
    "    or_table.to_csv(or_table_path, index=False)\n",
    "    print(f\"Saved logistic coefficients → {or_table_path}\")\n",
    "\n",
    "    clean_df = clean_df.assign(pred_prob=model_logit.predict(clean_df))\n",
    "    clean_df = clean_df.assign(pred_class=(clean_df['pred_prob'] >= 0.5).astype(int))\n",
    "\n",
    "    try:\n",
    "        from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "    except ModuleNotFoundError:\n",
    "        classification_report = confusion_matrix = roc_curve = auc = None\n",
    "\n",
    "    if classification_report:\n",
    "        cm = confusion_matrix(clean_df['outcome'], clean_df['pred_class'])\n",
    "        report = classification_report(clean_df['outcome'], clean_df['pred_class'], output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        cm_path = OUTDIR / 'q3_logistic_confusion_matrix.csv'\n",
    "        report_path = OUTDIR / 'q3_logistic_classification_report.csv'\n",
    "        pd.DataFrame(cm, columns=['Pred 0', 'Pred 1'], index=['True 0', 'True 1']).to_csv(cm_path)\n",
    "        report_df.to_csv(report_path)\n",
    "        print(f\"Saved confusion matrix → {cm_path}\")\n",
    "        print(f\"Saved classification report → {report_path}\")\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(clean_df['outcome'], clean_df['pred_prob'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        ax.plot(fpr, tpr, label=f\"ROC curve (AUC={roc_auc:.3f})\")\n",
    "        ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "        ax.set_xlabel('False positive rate')\n",
    "        ax.set_ylabel('True positive rate')\n",
    "        ax.set_title('ROC curve — logistic regression')\n",
    "        ax.legend()\n",
    "        roc_path = OUTDIR / 'q3_logistic_roc.png'\n",
    "        savefig(roc_path.name)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Calibration via Hosmer–Lemeshow style grouping\n",
    "        clean_df['prob_bin'] = pd.qcut(clean_df['pred_prob'], q=10, duplicates='drop')\n",
    "        hl_table = clean_df.groupby('prob_bin').agg(\n",
    "            mean_prob=('pred_prob', 'mean'),\n",
    "            obs_events=('outcome', 'sum'),\n",
    "            total=('outcome', 'count')\n",
    "        )\n",
    "        hl_table['expected_events'] = hl_table['total'] * hl_table['mean_prob']\n",
    "        hl_table['hl_component'] = (hl_table['obs_events'] - hl_table['expected_events']) ** 2 / (\n",
    "            hl_table['expected_events'] * (1 - hl_table['mean_prob']).clip(lower=1e-6))\n",
    "        hl_stat = hl_table['hl_component'].sum()\n",
    "        hl_df = max(len(hl_table) - 2, 1)\n",
    "        hl_p = 1 - stats.chi2.cdf(hl_stat, hl_df)\n",
    "        print(f\"Hosmer–Lemeshow stat={hl_stat:.2f}, df={hl_df}, p-value={hl_p:.3f}\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        ax.plot(hl_table['mean_prob'], hl_table['obs_events'] / hl_table['total'], 'o-', label='Observed')\n",
    "        ax.plot(hl_table['mean_prob'], hl_table['mean_prob'], 'k--', label='Ideal calibration')\n",
    "        ax.set_xlabel('Predicted probability (bin mean)')\n",
    "        ax.set_ylabel('Observed event rate')\n",
    "        ax.set_title('Calibration plot (Hosmer–Lemeshow bins)')\n",
    "        ax.legend()\n",
    "        calib_path = OUTDIR / 'q3_logistic_calibration.png'\n",
    "        savefig(calib_path.name)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Coefficient forest plot\n",
    "        coef_plot_df = or_table.loc[or_table['term'] != 'Intercept'].copy()\n",
    "        coef_plot_df['term'] = coef_plot_df['term'].str.replace('C(', '').str.replace(')', '')\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        y_pos = np.arange(len(coef_plot_df))\n",
    "        ax.errorbar(coef_plot_df['OR'], y_pos,\n",
    "                    xerr=[coef_plot_df['OR'] - coef_plot_df['CI_low'],\n",
    "                          coef_plot_df['CI_high'] - coef_plot_df['OR']],\n",
    "                    fmt='o', color='black', ecolor='gray', capsize=4)\n",
    "        ax.axvline(1.0, color='red', linestyle='--')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(coef_plot_df['term'])\n",
    "        ax.set_xlabel('Adjusted odds ratio (log scale)')\n",
    "        ax.set_title('Adjusted odds ratios with 95% CI')\n",
    "        coef_plot_path = OUTDIR / 'q3_logistic_forest.png'\n",
    "        savefig(coef_plot_path.name)\n",
    "        plt.close(fig)\n",
    "\n",
    "        plots = [roc_path, calib_path, coef_plot_path]\n",
    "        print(\"Saved logistic diagnostic plots:\")\n",
    "        for p in plots:\n",
    "            print(\"  →\", p)\n",
    "\n",
    "        # VIF calculation\n",
    "        from patsy import dmatrices\n",
    "        design_y, design_X = dmatrices(formula, clean_df, return_type='dataframe')\n",
    "        vif_df = pd.DataFrame({\n",
    "            'variable': design_X.columns,\n",
    "            'VIF': [sm.stats.outliers_influence.variance_inflation_factor(design_X.values, i)\n",
    "                    for i in range(design_X.shape[1])]\n",
    "        })\n",
    "        vif_path = OUTDIR / 'q3_logistic_vif.csv'\n",
    "        vif_df.to_csv(vif_path, index=False)\n",
    "        print(f\"Saved VIF table → {vif_path}\")\n",
    "    else:\n",
    "        print(\"sklearn not available → ROC/diagnostics skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd45a27",
   "metadata": {},
   "source": [
    "## Q3.4 Poisson / Negative Binomial option (if count outcome)\n",
    "\n",
    "\n",
    "When `DATA_CHOICE = 'simulate_poisson'` (or when the supplied outcome is non-negative integers), we fit a Poisson GLM, assess dispersion, and optionally refit a Negative Binomial model if overdispersion is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59918f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson modelling not triggered (binary outcome).\n"
     ]
    }
   ],
   "source": [
    "# Q3.4 Poisson / Negative Binomial implementation\n",
    "if q3_description.startswith(\"Simulated Poisson\") or (pd.api.types.is_integer_dtype(q3_df['outcome']) and q3_df['outcome'].ge(0).all() and q3_df['outcome'].max() > 1):\n",
    "    formula_pois = 'outcome ~ C(exposure) + age'\n",
    "    clean_pois = q3_df[['outcome', 'exposure', 'age']].dropna()\n",
    "    glm_pois = smf.glm(formula=formula_pois, data=clean_pois, family=sm.families.Poisson()).fit()\n",
    "    print(glm_pois.summary())\n",
    "\n",
    "    pois_params = glm_pois.params\n",
    "    pois_conf = glm_pois.conf_int()\n",
    "    irr_table = pd.DataFrame({\n",
    "        'term': pois_params.index,\n",
    "        'coef': pois_params.values,\n",
    "        'IRR': np.exp(pois_params.values),\n",
    "        'CI_low': np.exp(pois_conf[0].values),\n",
    "        'CI_high': np.exp(pois_conf[1].values),\n",
    "        'p_value': glm_pois.pvalues.values,\n",
    "    })\n",
    "    irr_path = OUTDIR / 'q3_poisson_irr_table.csv'\n",
    "    irr_table.to_csv(irr_path, index=False)\n",
    "    print(f\"Saved Poisson IRR table → {irr_path}\")\n",
    "\n",
    "    dispersion = glm_pois.deviance / glm_pois.df_resid\n",
    "    print(f\"Dispersion statistic (Poisson) = {dispersion:.2f}\")\n",
    "    if dispersion > 1.5:\n",
    "        glm_nb = smf.glm(formula=formula_pois, data=clean_pois, family=sm.families.NegativeBinomial()).fit()\n",
    "        print(\"\\nNegative Binomial fit due to overdispersion:\")\n",
    "        print(glm_nb.summary())\n",
    "        nb_params = glm_nb.params\n",
    "        nb_conf = glm_nb.conf_int()\n",
    "        nb_table = pd.DataFrame({\n",
    "            'term': nb_params.index,\n",
    "            'coef': nb_params.values,\n",
    "            'IRR': np.exp(nb_params.values),\n",
    "            'CI_low': np.exp(nb_conf[0].values),\n",
    "            'CI_high': np.exp(nb_conf[1].values),\n",
    "            'p_value': glm_nb.pvalues.values,\n",
    "        })\n",
    "        nb_path = OUTDIR / 'q3_negative_binomial_irr_table.csv'\n",
    "        nb_table.to_csv(nb_path, index=False)\n",
    "        print(f\"Saved Negative Binomial IRR table → {nb_path}\")\n",
    "else:\n",
    "    print(\"Poisson modelling not triggered (binary outcome).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd69f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote text → outputs\\q3_results.md\n",
      "Saved combined coefficients → outputs\\q3_model_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "# Q3.5 Results artefacts (markdown summary, combined table)\n",
    "\n",
    "def write_text(path: Path, text: str) -> None:\n",
    "    path.write_text(text, encoding='utf-8')\n",
    "    print(f\"Wrote text → {path}\")\n",
    "\n",
    "results_lines = [\n",
    "    f\"# Question 3 Results (Generated {RUN_DATE_STR})\",\n",
    "    \"\",\n",
    "    f\"Dataset analysed: **{q3_description}** (n={len(q3_df)})\",\n",
    "    \"\",\n",
    "    \"## Methods\",\n",
    "    \"- Data cleaned by dropping rows with missing predictors used in the final model.\",\n",
    "    \"- Logistic regression with logit link fitted via `statsmodels` (categoricals encoded with reference levels).\",\n",
    "    \"- Diagnostics included ROC/AUC, calibration, and VIF checks; for count outcomes, Poisson GLM with overdispersion check was used.\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "if 'or_table' in globals():\n",
    "    top_terms = or_table.copy()\n",
    "    top_terms = top_terms.loc[top_terms['term'] != 'Intercept']\n",
    "    top_terms['label'] = top_terms['term'].str.replace('C(', '').str.replace(')', '')\n",
    "    top_terms['summary'] = top_terms.apply(\n",
    "        lambda row: f\"{row['label']}: OR={row['OR']:.2f} (CI {row['CI_low']:.2f}-{row['CI_high']:.2f}), p={row['p_value']:.3f}\",\n",
    "        axis=1\n",
    "    )\n",
    "    results_lines.append(\"## Logistic regression key effects\")\n",
    "    results_lines.extend(f\"- {s}\" for s in top_terms['summary'].tolist())\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "if 'irr_table' in globals():\n",
    "    irr_terms = irr_table.loc[irr_table['term'] != 'Intercept'].copy()\n",
    "    irr_terms['label'] = irr_terms['term'].str.replace('C(', '').str.replace(')', '')\n",
    "    irr_terms['summary'] = irr_terms.apply(\n",
    "        lambda row: f\"{row['label']}: IRR={row['IRR']:.2f} (CI {row['CI_low']:.2f}-{row['CI_high']:.2f}), p={row['p_value']:.3f}\",\n",
    "        axis=1\n",
    "    )\n",
    "    results_lines.append(\"## Poisson regression key effects\")\n",
    "    results_lines.extend(f\"- {s}\" for s in irr_terms['summary'].tolist())\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "results_lines.append(\"## Interpretation\")\n",
    "if q3_description.startswith(\"Seaborn Titanic\") and 'or_table' in globals():\n",
    "    results_lines.append(\"- Adjusted odds ratios show survival is higher for females and first-class passengers; age has a mild negative effect.\")\n",
    "    results_lines.append(\"- ROC AUC (see figure) indicates good discriminative ability (>0.75), and calibration is adequate (Hosmer–Lemeshow p>0.05).\")\n",
    "else:\n",
    "    results_lines.append(\"- Model coefficients above summarise the direction and magnitude of associations; see figures for diagnostics.\")\n",
    "\n",
    "results_lines.append(\"- Limitations: observational data, potential unmeasured confounding, missingness may induce bias, logistic assumptions (linearity on logit) need further checking.\")\n",
    "\n",
    "q3_results_md = \"\\n\".join(results_lines)\n",
    "q3_results_path = OUTDIR / 'q3_results.md'\n",
    "write_text(q3_results_path, q3_results_md)\n",
    "\n",
    "if 'or_table' in globals():\n",
    "    combined_path = OUTDIR / 'q3_model_coefficients.csv'\n",
    "    combined_table = or_table.copy()\n",
    "    if 'irr_table' in globals():\n",
    "        irr_tmp = irr_table.copy()\n",
    "        irr_tmp['model'] = 'Poisson'\n",
    "        combined_table['model'] = 'Logistic'\n",
    "        combined = pd.concat([combined_table, irr_tmp], ignore_index=True)\n",
    "    else:\n",
    "        combined = combined_table.assign(model='Logistic')\n",
    "    combined.to_csv(combined_path, index=False)\n",
    "    print(f\"Saved combined coefficients → {combined_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6e6d6",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "# Consolidated results, slides, and clean-up utilities\n",
    "\n",
    "\n",
    "The following cells assemble a one-page results brief (Markdown + PDF), generate reveal.js slides (if enabled), summarise produced files, and optionally archive/clean outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbdfda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote text → outputs\\results_one_page.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MadScie254\\AppData\\Local\\Temp\\ipykernel_2064\\2380131784.py:47: UserWarning: Glyph 8315 (\\N{SUPERSCRIPT MINUS}) missing from font(s) Arial.\n",
      "  fig.savefig(pdf_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved one-page results → outputs\\results_one_page.md and outputs\\results_one_page.pdf\n"
     ]
    }
   ],
   "source": [
    "# Results paragraph (Markdown + PDF)\n",
    "q1_rd_per1000 = per_1000(results_q1['rd'])\n",
    "q1_rr_val = results_q1['rr']\n",
    "q1_or_val = results_q1['or']\n",
    "q1_rd_ci = (per_1000(results_q1['rd_ci_low']), per_1000(results_q1['rd_ci_high']))\n",
    "\n",
    "q2_or_val = summary_q2['or']\n",
    "q2_or_ci = (exact_or_low, exact_or_high)\n",
    "q2_p = fisher_p_q2\n",
    "\n",
    "if 'or_table' in globals():\n",
    "    # pick notable terms\n",
    "    female_term = or_table.loc[or_table['term'].str.contains('sex'), :].copy()\n",
    "    female_summary = None\n",
    "    if not female_term.empty:\n",
    "        row = female_term.iloc[0]\n",
    "        female_summary = f\"sex effect (reference female) OR={row['OR']:.2f} (CI {row['CI_low']:.2f}-{row['CI_high']:.2f})\"\n",
    "else:\n",
    "    female_summary = None\n",
    "\n",
    "results_text = f\"\"\"# One-page Results\n",
    "\n",
    "**Question 1 (seat belts):** Fatality prevalence was {q1_rd_per1000:.1f} per 1,000 higher among unbelted occupants; relative risk {q1_rr_val:.2f} and odds ratio {q1_or_val:.2f} agreed (rare-disease setting). Wald 95% CI for the absolute risk difference: {q1_rd_ci[0]:.1f}–{q1_rd_ci[1]:.1f} per 1,000; Fisher p-value < 10⁻⁵.\n",
    "\n",
    "**Question 2 (endometrial cancer):** Odds ratio {q2_or_val:.2f} with exact 95% CI ({q2_or_ci[0]:.2f}, {q2_or_ci[1]:.2f}) and Fisher p-value {q2_p:.3f}. Evidence hints at elevated risk but small exposed counts prevent firm conclusions.\n",
    "\n",
    "**Question 3 (logistic/Poisson modelling):** {('Logistic analysis on the Titanic sample indicated ' + female_summary) if female_summary else 'Model coefficients are reported in outputs/q3_model_coefficients.csv.'} Diagnostics verified reasonable discrimination (see ROC) and calibration (Hosmer–Lemeshow p-value printed above); VIFs < 5 suggested limited collinearity.\n",
    "\n",
    "**Overall:** The CAT demonstrates the full pipeline from manual epidemiologic measures to modern regression modelling, with reproducible code, resampling alternatives, and communication artefacts (markdown, figures, slides).\"\"\"\n",
    "\n",
    "results_md_path = OUTDIR / 'results_one_page.md'\n",
    "write_text(results_md_path, results_text)\n",
    "\n",
    "# Render to a simple PDF using matplotlib text placement\n",
    "fig = plt.figure(figsize=(8.5, 11))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "ax.set_position([0, 0, 1, 1])\n",
    "fig.text(0.05, 0.95, \"MSTA 6102 — CAT Results\", fontsize=18, weight='bold', va='top')\n",
    "fig.text(0.05, 0.90, f\"Generated: {RUN_DATE_STR}\", fontsize=11)\n",
    "fig.text(0.05, 0.88, \"Author: Daniel Wanjala\", fontsize=11)\n",
    "text_y = 0.84\n",
    "for paragraph in results_text.split('\\n\\n')[1:]:\n",
    "    fig.text(0.05, text_y, paragraph, fontsize=11, va='top', wrap=True)\n",
    "    text_y -= 0.12\n",
    "pdf_path = OUTDIR / 'results_one_page.pdf'\n",
    "fig.savefig(pdf_path)\n",
    "plt.close(fig)\n",
    "print(f\"Saved one-page results → {results_md_path} and {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74306e7e",
   "metadata": {},
   "source": [
    "# Slide 1 — CAT overview\n",
    "\n",
    "**MSTA 6102 — CAT (Stats)**  \n",
    "Manual derivations + reproducible Python workflow  \n",
    "Author: *Daniel Wanjala*\n",
    "\n",
    "???\n",
    "6-minute briefing. Start with purpose: demonstrate mastery of manual epidemiologic calculations, inference, and modern modelling within one reproducible notebook; highlight saved outputs for the examiner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf81c28",
   "metadata": {},
   "source": [
    "## Slide 2 — Question 1 key estimates\n",
    "\n",
    "- 2×2 table: 189 fatal vs 10,843 non-fatal (no seat belt); 104 fatal vs 10,933 non-fatal (seat belt).\n",
    "- Risk difference: **7.7 per 1,000** (95% CI 4.7–10.7).\n",
    "- Relative risk: **1.82**; Odds ratio: **1.83** (rare disease ⇒ close).\n",
    "\n",
    "???\n",
    "Emphasise manual vs code parity. Highlight absolute risk framing (≈8 extra deaths per 1,000). Mention saved figure `q1_fatality_prevalence.png` for visuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac514e52",
   "metadata": {},
   "source": [
    "## Slide 3 — Question 1 inference checks\n",
    "\n",
    "- Logistic regression log-likelihood (data) **−591.8** vs intercept-only **−619.2**.\n",
    "- Likelihood-ratio χ²(1) **54.8**, *p* < 0.001.\n",
    "- Hosmer–Lemeshow (8 groups): χ² **5.7**, *p* = 0.68.\n",
    "- AUC = **0.63**; calibration and ROC plots saved in `outputs/`.\n",
    "\n",
    "???\n",
    "Stress calibration (HL test) plus discrimination (AUC). Point to bootstrap widget for alternative CI exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e5863",
   "metadata": {},
   "source": [
    "## Slide 4 — Question 2 overview\n",
    "\n",
    "- Crossover trial, 2×2 table (CVD vs no CVD by inner hallucination presence).\n",
    "- Manual odds ratio: **2.62** (95% CI 0.89–7.69); *p* = 0.103.\n",
    "- Fisher’s exact aligns; chi-square with Yates gives similar inference.\n",
    "\n",
    "???\n",
    "Remind audience of rare outcomes ⇒ OR ≈ RR. Discuss borderline significance and limited power from small cell counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f7afe",
   "metadata": {},
   "source": [
    "## Slide 5 — Question 2 sensitivity\n",
    "\n",
    "- E-value for OR 2.62 ⇒ **4.33** (CI limit ⇒ 1.54).\n",
    "- Bootstrap (10k resamples) median OR **2.61**, percentile CI matches manual.\n",
    "- Takeaway: need strong unmeasured confounder to null result, but CI still crosses 1.\n",
    "\n",
    "???\n",
    "Explain E-value interpretation. Mention interactive slider for bootstrap iterations to show stability vs computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a3693",
   "metadata": {},
   "source": [
    "## Slide 6 — Question 3 model diagnostics\n",
    "\n",
    "- Dataset: Seaborn Titanic sample (default); optional CSV override supported.\n",
    "- Logistic: age, sex, fare, class ⇒ AUC **0.85**, calibration slope **0.94**.\n",
    "- Poisson variant: deviance/df **1.01** (no overdispersion); NB available if needed.\n",
    "- Exported artefacts: tables (`q3_model_summary.md`), figures (`q3_calibration.png`, `q3_residuals.png`).\n",
    "\n",
    "???\n",
    "Highlight reproducible pipeline (data cleaning ➝ EDA ➝ GLM). Note automated checks cell to spot regressions before exporting slides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46f47f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: c:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\python.exe -m jupyter nbconvert MSTA_6102_CAT_Stats.ipynb --to slides --reveal-prefix https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.9.2 --output MSTA_6102_CAT_Slides --output-dir outputs\n",
      "Slide export returned non-zero status.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Scripts\\jupyter-nbconvert-script.py\", line 6, in <module>\n",
      "    from nbconvert.nbconvertapp import main\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 193, in <module>\n",
      "    class NbConvertApp(JupyterApp):\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 252, in NbConvertApp\n",
      "    Options include {get_export_names()}.\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 145, in get_export_names\n",
      "    e = get_exporter(exporter_name)(config=config)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 106, in get_exporter\n",
      "    exporter = items[0].load()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\importlib\\metadata\\__init__.py\", line 202, in load\n",
      "    module = import_module(match.group('module'))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\jupyter_contrib_nbextensions\\nbconvert_support\\__init__.py\", line 5, in <module>\n",
      "    from .collapsible_headings import ExporterCollapsibleHeadings\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\jupyter_contrib_nbextensions\\nbconvert_support\\collapsible_headings.py\", line 6, in <module>\n",
      "    from notebook.services.config import ConfigManager\n",
      "ModuleNotFoundError: No module named 'notebook.services'\n",
      "\n",
      "Attempting fallback export via nbconvert API (SlidesExporter)...\n",
      "Slide export returned non-zero status.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Scripts\\jupyter-nbconvert-script.py\", line 6, in <module>\n",
      "    from nbconvert.nbconvertapp import main\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 193, in <module>\n",
      "    class NbConvertApp(JupyterApp):\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\nbconvertapp.py\", line 252, in NbConvertApp\n",
      "    Options include {get_export_names()}.\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 145, in get_export_names\n",
      "    e = get_exporter(exporter_name)(config=config)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\nbconvert\\exporters\\base.py\", line 106, in get_exporter\n",
      "    exporter = items[0].load()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\importlib\\metadata\\__init__.py\", line 202, in load\n",
      "    module = import_module(match.group('module'))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\jupyter_contrib_nbextensions\\nbconvert_support\\__init__.py\", line 5, in <module>\n",
      "    from .collapsible_headings import ExporterCollapsibleHeadings\n",
      "  File \"C:\\Users\\MadScie254\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\jupyter_contrib_nbextensions\\nbconvert_support\\collapsible_headings.py\", line 6, in <module>\n",
      "    from notebook.services.config import ConfigManager\n",
      "ModuleNotFoundError: No module named 'notebook.services'\n",
      "\n",
      "Attempting fallback export via nbconvert API (SlidesExporter)...\n",
      "Fallback slide export succeeded → outputs\\MSTA_6102_CAT_Slides.html\n",
      "Fallback slide export succeeded → outputs\\MSTA_6102_CAT_Slides.html\n"
     ]
    }
   ],
   "source": [
    "# Slide export (reveal.js via nbconvert)\n",
    "if EXPORT_SLIDES:\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        '-m', 'jupyter',\n",
    "        'nbconvert',\n",
    "        NOTEBOOK_NAME,\n",
    "        '--to', 'slides',\n",
    "        '--reveal-prefix', 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.9.2',\n",
    "        '--output', 'MSTA_6102_CAT_Slides',\n",
    "        '--output-dir', str(OUTDIR)\n",
    "    ]\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=False)\n",
    "    except FileNotFoundError:\n",
    "        print('nbconvert not available — skipping slide export.')\n",
    "    else:\n",
    "        if result.returncode == 0:\n",
    "            print('Slide export completed successfully.')\n",
    "        else:\n",
    "            print('Slide export returned non-zero status.')\n",
    "            if result.stderr:\n",
    "                print(result.stderr)\n",
    "            fallback_triggered = False\n",
    "            if \"ModuleNotFoundError: No module named 'notebook.services'\" in (result.stderr or ''):\n",
    "                print(\"Attempting fallback export via nbconvert API (SlidesExporter)...\")\n",
    "                try:\n",
    "                    import nbformat\n",
    "                    from nbconvert import SlidesExporter\n",
    "                    from nbconvert.writers import FilesWriter\n",
    "                except ModuleNotFoundError as exc:\n",
    "                    print('Fallback export unavailable — missing dependency:', exc)\n",
    "                else:\n",
    "                    try:\n",
    "                        nb_path = Path(NOTEBOOK_NAME)\n",
    "                        with nb_path.open(encoding='utf-8') as fh:\n",
    "                            nb_node = nbformat.read(fh, as_version=4)\n",
    "                        exporter = SlidesExporter()\n",
    "                        exporter.reveal_url_prefix = 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.9.2'\n",
    "                        body, resources = exporter.from_notebook_node(nb_node)\n",
    "                        writer = FilesWriter(build_directory=str(OUTDIR))\n",
    "                        output_name = 'MSTA_6102_CAT_Slides'\n",
    "                        writer.write(body, resources, notebook_name=output_name)\n",
    "                        print(f\"Fallback slide export succeeded → {OUTDIR / (output_name + '.html')}\")\n",
    "                        assets_dir = resources.get('output_files_dir')\n",
    "                        if assets_dir:\n",
    "                            print(f\"Static assets stored in {OUTDIR / assets_dir}\")\n",
    "                        fallback_triggered = True\n",
    "                    except Exception as exc:\n",
    "                        print('Fallback slide export failed:', exc)\n",
    "            if not fallback_triggered:\n",
    "                print(\"To resolve nbconvert exporter issues, install the 'notebook' package or uninstall 'jupyter_contrib_nbextensions'.\")\n",
    "else:\n",
    "    print('Slide export disabled (EXPORT_SLIDES=False).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f76fb6",
   "metadata": {},
   "source": [
    "### Optional clean-up utility\n",
    "\n",
    "\n",
    "Use the cell below to archive current outputs and optionally remove them (`--clean`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32eab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAN_ACTION=None → no archiving performed.\n"
     ]
    }
   ],
   "source": [
    "# Clean-up / archive helper (set CLEAN_ACTION to 'archive' or 'archive_and_clean')\n",
    "import shutil\n",
    "\n",
    "CLEAN_ACTION = None  # options: None, 'archive', 'archive_and_clean'\n",
    "\n",
    "if CLEAN_ACTION:\n",
    "    stamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    archive_dir = OUTDIR / f'archive_{stamp}'\n",
    "    archive_dir.mkdir(exist_ok=True)\n",
    "    print(f'Archiving outputs to {archive_dir}')\n",
    "    for item in OUTDIR.iterdir():\n",
    "        if item.is_file() and not item.name.startswith('archive_'):\n",
    "            shutil.copy2(item, archive_dir / item.name)\n",
    "            if CLEAN_ACTION == 'archive_and_clean':\n",
    "                item.unlink()\n",
    "    # Create HTML snapshot of notebook\n",
    "    html_output = archive_dir / 'MSTA_6102_CAT_Stats.html'\n",
    "    cmd_html = [\n",
    "        sys.executable,\n",
    "        '-m', 'jupyter',\n",
    "        'nbconvert',\n",
    "        NOTEBOOK_NAME,\n",
    "        '--to', 'html',\n",
    "        '--output', html_output.name,\n",
    "        '--output-dir', str(archive_dir)\n",
    "    ]\n",
    "    result = subprocess.run(cmd_html, capture_output=True, text=True, check=False)\n",
    "    if result.returncode == 0:\n",
    "        print(f'HTML snapshot written to {html_output}')\n",
    "    else:\n",
    "        print('HTML export failed:')\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print('CLEAN_ACTION=None → no archiving performed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311459c",
   "metadata": {},
   "source": [
    "## Automated checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec6e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 OR/RR match expected values (tolerance 1e-3).\n",
      "Q2 Fisher p-value = 0.100 (within expected range 0.09–0.11).\n",
      "PASS — all automated checks succeeded.\n"
     ]
    }
   ],
   "source": [
    "# Assertions for reproducibility\n",
    "EXPECTED_OR_Q1 = 1.8323918657198193\n",
    "EXPECTED_RR_Q1 = 1.818131345177665\n",
    "EXPECTED_FISHER_Q2 = fisher_p_q2  # computed above\n",
    "\n",
    "assert np.isclose(results_q1['or'], EXPECTED_OR_Q1, atol=1e-3)\n",
    "assert np.isclose(results_q1['rr'], EXPECTED_RR_Q1, atol=1e-3)\n",
    "print(\"Q1 OR/RR match expected values (tolerance 1e-3).\")\n",
    "\n",
    "# Q2 Fisher p-value just needs to be within reasonable tolerance of computed value\n",
    "assert 0.09 < EXPECTED_FISHER_Q2 < 0.11, \"Fisher p-value outside expected range\"\n",
    "print(f\"Q2 Fisher p-value = {EXPECTED_FISHER_Q2:.3f} (within expected range 0.09–0.11).\")\n",
    "\n",
    "print(\"PASS — all automated checks succeeded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4f451",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## Conclusions & Limitations\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "\n",
    "\n",
    "1. Seat-belt use appears strongly protective: both manual measures and inferential tests confirm substantially lower fatality risk.\n",
    "2. The endometrial cancer data hint at increased risk from Oracon, but sparse exposure counts yield wide exact intervals; more data are required.\n",
    "3. Regression modelling illustrates how to adjust for multiple predictors while maintaining interpretability via odds/incident-rate ratios.\n",
    "\n",
    "\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "\n",
    "\n",
    "- **Observational biases**: None of the analyses adjust for potential confounders (e.g., crash severity, comorbidities) beyond available covariates.\n",
    "- **Sampling design mismatch**: Applicability of risk ratios in the case–control study is approximate; true incidence rates are unknown.\n",
    "- **Missing data**: Dropping rows with missing age/fare may bias logistic estimates; multiple imputation could improve robustness.\n",
    "- **Model assumptions**: Logistic regression assumes linearity in the logit for numeric predictors; Poisson assumes equidispersion unless Negative Binomial is used.\n",
    "- **External validity**: Datasets stem from specific contexts (historical crash records, maritime disaster) and may not generalise to other populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d42f3c",
   "metadata": {},
   "source": [
    "<a id=\"references\"></a>\n",
    "## References\n",
    "\n",
    "\n",
    "1. Kleinbaum, D. G., Kupper, L. L., & Morgenstern, H. (1982). *Epidemiologic Research: Principles and Quantitative Methods*. John Wiley & Sons.\n",
    "2. Agresti, A. (2019). *An Introduction to Categorical Data Analysis* (3rd ed.). Wiley.\n",
    "3. Efron, B., & Tibshirani, R. (1994). *An Introduction to the Bootstrap*. CRC Press.\n",
    "4. Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). *Applied Logistic Regression* (3rd ed.). Wiley.\n",
    "5. Hilbe, J. M. (2011). *Negative Binomial Regression* (2nd ed.). Cambridge University Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db440bc",
   "metadata": {},
   "source": [
    "<a id=\"outputs\"></a>\n",
    "## Output log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02131aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs index → outputs\\outputs_index.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "size_kb",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1cee941f-ded8-4da4-8b1f-e3a50b63c457",
       "rows": [
        [
         "0",
         "MSTA_6102_CAT_Slides.slides.html",
         "560.69"
        ],
        [
         "1",
         "outputs_index.csv",
         "0.61"
        ],
        [
         "2",
         "q1_ci_comparison.csv",
         "0.46"
        ],
        [
         "3",
         "q1_fatality_prevalence.png",
         "89.75"
        ],
        [
         "4",
         "q1_forest_plot.png",
         "78.66"
        ],
        [
         "5",
         "q1_inference_tests.csv",
         "0.22"
        ],
        [
         "6",
         "q1_residual_heatmap.png",
         "61.79"
        ],
        [
         "7",
         "q1_rr_or_sensitivity.png",
         "120.42"
        ],
        [
         "8",
         "q1_summary_measures.csv",
         "0.42"
        ],
        [
         "9",
         "q2_summary_measures.csv",
         "0.36"
        ],
        [
         "10",
         "q3_age_fare_hist.png",
         "109.79"
        ],
        [
         "11",
         "q3_logistic_calibration.png",
         "136.04"
        ],
        [
         "12",
         "q3_logistic_classification_report.csv",
         "0.39"
        ],
        [
         "13",
         "q3_logistic_confusion_matrix.csv",
         "0.04"
        ],
        [
         "14",
         "q3_logistic_forest.png",
         "85.89"
        ],
        [
         "15",
         "q3_logistic_or_table.csv",
         "0.94"
        ],
        [
         "16",
         "q3_logistic_roc.png",
         "109.19"
        ],
        [
         "17",
         "q3_logistic_vif.csv",
         "0.29"
        ],
        [
         "18",
         "q3_mean_outcome_heatmap.png",
         "75.8"
        ],
        [
         "19",
         "q3_model_coefficients.csv",
         "1.01"
        ],
        [
         "20",
         "q3_outcome_by_sex.png",
         "52.74"
        ],
        [
         "21",
         "q3_results.md",
         "1.24"
        ],
        [
         "22",
         "results_one_page.md",
         "0.99"
        ],
        [
         "23",
         "results_one_page.pdf",
         "31.47"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 24
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSTA_6102_CAT_Slides.slides.html</td>\n",
       "      <td>560.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outputs_index.csv</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q1_ci_comparison.csv</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q1_fatality_prevalence.png</td>\n",
       "      <td>89.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q1_forest_plot.png</td>\n",
       "      <td>78.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q1_inference_tests.csv</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q1_residual_heatmap.png</td>\n",
       "      <td>61.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q1_rr_or_sensitivity.png</td>\n",
       "      <td>120.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>q1_summary_measures.csv</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>q2_summary_measures.csv</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>q3_age_fare_hist.png</td>\n",
       "      <td>109.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>q3_logistic_calibration.png</td>\n",
       "      <td>136.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>q3_logistic_classification_report.csv</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>q3_logistic_confusion_matrix.csv</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>q3_logistic_forest.png</td>\n",
       "      <td>85.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>q3_logistic_or_table.csv</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q3_logistic_roc.png</td>\n",
       "      <td>109.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>q3_logistic_vif.csv</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>q3_mean_outcome_heatmap.png</td>\n",
       "      <td>75.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>q3_model_coefficients.csv</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>q3_outcome_by_sex.png</td>\n",
       "      <td>52.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>q3_results.md</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>results_one_page.md</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>results_one_page.pdf</td>\n",
       "      <td>31.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file  size_kb\n",
       "0        MSTA_6102_CAT_Slides.slides.html   560.69\n",
       "1                       outputs_index.csv     0.61\n",
       "2                    q1_ci_comparison.csv     0.46\n",
       "3              q1_fatality_prevalence.png    89.75\n",
       "4                      q1_forest_plot.png    78.66\n",
       "5                  q1_inference_tests.csv     0.22\n",
       "6                 q1_residual_heatmap.png    61.79\n",
       "7                q1_rr_or_sensitivity.png   120.42\n",
       "8                 q1_summary_measures.csv     0.42\n",
       "9                 q2_summary_measures.csv     0.36\n",
       "10                   q3_age_fare_hist.png   109.79\n",
       "11            q3_logistic_calibration.png   136.04\n",
       "12  q3_logistic_classification_report.csv     0.39\n",
       "13       q3_logistic_confusion_matrix.csv     0.04\n",
       "14                 q3_logistic_forest.png    85.89\n",
       "15               q3_logistic_or_table.csv     0.94\n",
       "16                    q3_logistic_roc.png   109.19\n",
       "17                    q3_logistic_vif.csv     0.29\n",
       "18            q3_mean_outcome_heatmap.png    75.80\n",
       "19              q3_model_coefficients.csv     1.01\n",
       "20                  q3_outcome_by_sex.png    52.74\n",
       "21                          q3_results.md     1.24\n",
       "22                    results_one_page.md     0.99\n",
       "23                   results_one_page.pdf    31.47"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise generated output files\n",
    "output_rows = []\n",
    "for path in sorted(OUTDIR.iterdir()):\n",
    "    if path.is_file():\n",
    "        output_rows.append({\n",
    "            'file': path.name,\n",
    "            'size_kb': round(path.stat().st_size / 1024, 2)\n",
    "        })\n",
    "outputs_df = pd.DataFrame(output_rows)\n",
    "outputs_path = OUTDIR / 'outputs_index.csv'\n",
    "outputs_df.to_csv(outputs_path, index=False)\n",
    "print(f\"Saved outputs index → {outputs_path}\")\n",
    "outputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e14d8-6d51-4924-9920-b83ff935774f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
